import React from "react";
import cv from "@techstark/opencv-js";
import {
  Hands,
  HAND_CONNECTIONS,
  type Results,
  type NormalizedLandmark,
} from "@mediapipe/hands";
import { drawConnectors, drawLandmarks } from "@mediapipe/drawing_utils";
import { loadFullBodyModels, getFullBodyCascade } from "./fullBodyDetection";
import type { CascadeClassifier } from "@techstark/opencv-js";

// çŠ¶æ€æšä¸¾
const CaptureState = {
  IDLE: "idle",
  VIDEO_LOADED: "video_loaded",
  DETECTING_BODY: "detecting_body",
  BODY_DETECTED: "body_detected",
  DETECTING_GESTURE: "detecting_gesture",
  GESTURE_DETECTED: "gesture_detected",
  COUNTDOWN: "countdown",
  CAPTURE: "capture",
  COMPLETED: "completed",
} as const;

type CaptureState = (typeof CaptureState)[keyof typeof CaptureState];

interface BodyRect {
  x: number;
  y: number;
  width: number;
  height: number;
}

// è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»
function calculateDistance(
  point1: NormalizedLandmark,
  point2: NormalizedLandmark
): number {
  const dx = point1.x - point2.x;
  const dy = point1.y - point2.y;
  const dz = point1.z - point2.z;
  return Math.sqrt(dx * dx + dy * dy + dz * dz);
}

// è¯†åˆ«OKæ‰‹åŠ¿
function recognizeOKGesture(landmarks: NormalizedLandmark[]): boolean {
  const thumbTip = landmarks[4];
  const indexTip = landmarks[8];
  const indexPip = landmarks[6];
  const middleTip = landmarks[12];
  const ringTip = landmarks[16];
  const pinkyTip = landmarks[20];
  const palmBase = landmarks[9];

  // æ£€æŸ¥å¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡æ˜¯å¦å½¢æˆåœ†åœˆ
  const thumbIndexDist = calculateDistance(thumbTip, indexTip);
  const isCircleFormed = thumbIndexDist < 0.08;

  // æ£€æŸ¥å…¶ä»–ä¸‰æ ¹æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´
  const middleExtended = middleTip.y < palmBase.y - 0.1;
  const ringExtended = ringTip.y < palmBase.y - 0.08;
  const pinkyExtended = pinkyTip.y < palmBase.y - 0.06;

  // ç¡®ä¿é£ŸæŒ‡æ˜¯å¼¯æ›²çš„
  const indexBent = indexPip.y < indexTip.y;

  return (
    isCircleFormed &&
    middleExtended &&
    ringExtended &&
    pinkyExtended &&
    indexBent
  );
}

export default function IntegratedVideoCapture(): React.JSX.Element {
  const videoRef = React.useRef<HTMLVideoElement>(null);
  const canvasRef = React.useRef<HTMLCanvasElement>(null);
  const capturedImageRef = React.useRef<HTMLCanvasElement>(null);
  const fileInputRef = React.useRef<HTMLInputElement>(null);

  const [state, setState] = React.useState<CaptureState>(CaptureState.IDLE);
  const [isLoading, setIsLoading] = React.useState<boolean>(true);
  const [error, setError] = React.useState<string | null>(null);
  const [statusMessage, setStatusMessage] = React.useState<string>("");
  const [countdown, setCountdown] = React.useState<number>(5);
  const [videoFile, setVideoFile] = React.useState<File | null>(null);
  const [isVideoPlaying, setIsVideoPlaying] = React.useState<boolean>(false);

  // æ—¶é—´è¿½è¸ª
  const bodyDetectionStartTime = React.useRef<number | null>(null);
  const lastBodyDetectedTime = React.useRef<number | null>(null);
  const gestureDetectionStartTime = React.useRef<number | null>(null);

  // å…¨èº«æ£€æµ‹ç›¸å…³
  const fullBodyCascadeRef = React.useRef<CascadeClassifier | null>(null);
  const lastBodyRectRef = React.useRef<BodyRect | null>(null);

  // MediaPipe Hands
  const handsRef = React.useRef<Hands | null>(null);
  const animationFrameRef = React.useRef<number | null>(null);
  const processingRef = React.useRef<boolean>(false);

  // æ€§èƒ½ä¼˜åŒ–ï¼šå¸§è®¡æ•°å™¨
  const frameCountRef = React.useRef<number>(0);

  // ä½¿ç”¨ ref å­˜å‚¨æœ€æ–°çš„çŠ¶æ€
  const stateRef = React.useRef(state);
  const countdownRef = React.useRef(countdown);
  const statusMessageRef = React.useRef(statusMessage);

  // åŒæ­¥ ref å€¼
  React.useEffect(() => {
    stateRef.current = state;
    countdownRef.current = countdown;
    statusMessageRef.current = statusMessage;
  }, [state, countdown, statusMessage]);

  // æ£€æµ‹å…¨èº«
  const detectFullBody = React.useCallback(
    (
      imageData: ImageData
    ): { count: number; rect: BodyRect | null; allRects: BodyRect[] } => {
      if (!fullBodyCascadeRef.current) {
        return { count: 0, rect: null, allRects: [] };
      }

      try {
        // åˆ›å»º Mat ä» ImageData
        const src = cv.matFromImageData(imageData);

        // è½¬æ¢ä¸ºç°åº¦å›¾
        const gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

        const bodies = new cv.RectVector();
        const msize = new cv.Size(0, 0);

        // ä½¿ç”¨åŸå§‹å°ºå¯¸è¿›è¡Œæ£€æµ‹ï¼Œæé«˜å‡†ç¡®åº¦
        fullBodyCascadeRef.current.detectMultiScale(
          gray,
          bodies,
          1.1,
          5,
          0,
          new cv.Size(50, 100), // åŸå§‹å°ºå¯¸çš„æœ€å°æ£€æµ‹åŒºåŸŸ
          msize
        );

        const count = bodies.size();
        const allRects: BodyRect[] = [];
        let largestRect: BodyRect | null = null;
        let largestArea = 0;

        // æ”¶é›†æ‰€æœ‰æ£€æµ‹åˆ°çš„èº«ä½“ï¼Œæ‰¾å‡ºé¢ç§¯æœ€å¤§çš„
        for (let i = 0; i < count; ++i) {
          const body = bodies.get(i);
          const rect = {
            x: body.x,
            y: body.y,
            width: body.width,
            height: body.height,
          };
          allRects.push(rect);

          const area = rect.width * rect.height;
          if (area > largestArea) {
            largestArea = area;
            largestRect = rect;
          }
        }

        gray.delete();
        src.delete();
        bodies.delete();

        return { count, rect: largestRect, allRects };
      } catch (err) {
        console.error("å…¨èº«æ£€æµ‹é”™è¯¯:", err);
        return { count: 0, rect: null, allRects: [] };
      }
    },
    []
  );

  // å¤„ç†è§†é¢‘å¸§
  const processFrame = React.useCallback(async () => {
    const video = videoRef.current;
    const canvas = canvasRef.current;
    const hands = handsRef.current;

    if (!video || !canvas || !hands) {
      console.log("processFrame: ç¼ºå°‘å¿…è¦å…ƒç´ ", {
        video: !!video,
        canvas: !!canvas,
        hands: !!hands,
      });
      return;
    }

    if (video.ended) {
      console.log("processFrame: è§†é¢‘å·²ç»“æŸ");
      return;
    }

    // å¦‚æœæ­£åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡æ­¤å¸§
    if (processingRef.current) {
      return;
    }

    // å¦‚æœè§†é¢‘æš‚åœï¼Œå°è¯•æ¢å¤æ’­æ”¾
    if (video.paused) {
      console.log("processFrame: è§†é¢‘æš‚åœï¼Œå°è¯•æ’­æ”¾");
      try {
        await video.play();
      } catch (err) {
        console.warn("processFrame: æ— æ³•è‡ªåŠ¨æ’­æ”¾è§†é¢‘", err);
      }
      return;
    }

    processingRef.current = true;

    try {
      const ctx = canvas.getContext("2d", { willReadFrequently: true });
      if (!ctx) {
        processingRef.current = false;
        return;
      }

      // ç»˜åˆ¶è§†é¢‘å¸§åˆ°canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const currentTime = Date.now();
      const currentState = stateRef.current;

      // å…¨èº«æ£€æµ‹é€»è¾‘
      if (
        currentState === CaptureState.VIDEO_LOADED ||
        currentState === CaptureState.DETECTING_BODY ||
        currentState === CaptureState.BODY_DETECTED
      ) {
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const { count, rect, allRects } = detectFullBody(imageData);

        console.log(`æ£€æµ‹ç»“æœ: æ£€æµ‹åˆ° ${count} äºº`, rect ? "æœ‰çŸ©å½¢" : "æ— çŸ©å½¢");

        if (count >= 1 && rect) {
          // æ£€æµ‹åˆ°è‡³å°‘ä¸€äººï¼Œé€‰æ‹©æœ€å¤§çš„
          lastBodyDetectedTime.current = currentTime;
          lastBodyRectRef.current = rect;

          if (currentState === CaptureState.VIDEO_LOADED) {
            console.log("çŠ¶æ€å˜æ›´: VIDEO_LOADED -> DETECTING_BODY");
            setState(CaptureState.DETECTING_BODY);
            bodyDetectionStartTime.current = currentTime;
            setStatusMessage("æ­£åœ¨æ£€æµ‹å…¨èº«...");
          } else if (currentState === CaptureState.DETECTING_BODY) {
            if (
              bodyDetectionStartTime.current &&
              currentTime - bodyDetectionStartTime.current >= 1000
            ) {
              setState(CaptureState.BODY_DETECTED);
              setStatusMessage("âœ“ å·²è¯†åˆ«åˆ°å…¨èº«");
              setTimeout(() => {
                setState(CaptureState.DETECTING_GESTURE);
                setStatusMessage("è¯·åšå‡ºOKæ‰‹åŠ¿");
              }, 1500);
            } else {
              setStatusMessage("æ­£åœ¨æ£€æµ‹å…¨èº«...");
            }
          } else if (currentState === CaptureState.BODY_DETECTED) {
            setStatusMessage("âœ“ å·²è¯†åˆ«åˆ°å…¨èº«");
          }

          // ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹åˆ°çš„èº«ä½“æ¡†
          allRects.forEach((r, index) => {
            const isLargest =
              r.x === rect.x &&
              r.y === rect.y &&
              r.width === rect.width &&
              r.height === rect.height;

            ctx.strokeStyle = isLargest ? "#00FF00" : "#FFFF00";
            ctx.lineWidth = isLargest ? 4 : 2;
            ctx.strokeRect(r.x, r.y, r.width, r.height);

            ctx.fillStyle = isLargest ? "#00FF00" : "#FFFF00";
            ctx.font = "bold 18px Arial";
            const label = isLargest ? `ä¸»ç›®æ ‡ (${index + 1})` : `${index + 1}`;
            ctx.fillText(label, r.x, r.y - 10);
          });

          // æ˜¾ç¤ºæ£€æµ‹äººæ•°
          const text =
            count === 1 ? "æ£€æµ‹åˆ° 1 äºº" : `æ£€æµ‹åˆ° ${count} äººï¼ˆå·²é€‰æ‹©æœ€å¤§è€…ï¼‰`;
          ctx.fillStyle = "#00FF00";
          ctx.font = "bold 24px Arial";
          ctx.fillText(text, 10, 40);
        } else {
          if (
            currentState === CaptureState.DETECTING_BODY ||
            currentState === CaptureState.BODY_DETECTED
          ) {
            if (
              lastBodyDetectedTime.current &&
              currentTime - lastBodyDetectedTime.current >= 1000
            ) {
              setState(CaptureState.VIDEO_LOADED);
              bodyDetectionStartTime.current = null;
              lastBodyDetectedTime.current = null;
              setStatusMessage("âŒ æœªè¯†åˆ«åˆ°å…¨èº«ï¼Œé‡æ–°å¼€å§‹");
              setTimeout(() => setStatusMessage(""), 2000);
            }
          }
        }
      }

      // æ‰‹åŠ¿æ£€æµ‹é€»è¾‘
      if (
        currentState === CaptureState.DETECTING_GESTURE ||
        currentState === CaptureState.GESTURE_DETECTED
      ) {
        // æ¯2å¸§æ£€æµ‹ä¸€æ¬¡å…¨èº«
        frameCountRef.current++;
        if (frameCountRef.current % 2 === 0) {
          const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
          const { count, rect } = detectFullBody(imageData);
          if (count >= 1 && rect) {
            // æ£€æµ‹åˆ°è‡³å°‘ä¸€äºº
            lastBodyDetectedTime.current = currentTime;
            lastBodyRectRef.current = rect;
          } else if (
            lastBodyDetectedTime.current &&
            currentTime - lastBodyDetectedTime.current >= 1000
          ) {
            setState(CaptureState.VIDEO_LOADED);
            bodyDetectionStartTime.current = null;
            lastBodyDetectedTime.current = null;
            gestureDetectionStartTime.current = null;
            frameCountRef.current = 0;
            setStatusMessage("âŒ å…¨èº«ä¸¢å¤±ï¼Œé‡æ–°å¼€å§‹");
            setTimeout(() => setStatusMessage(""), 2000);
            processingRef.current = false;
            return;
          }
        }

        // å‘é€åˆ° MediaPipe Hands è¿›è¡Œæ‰‹åŠ¿è¯†åˆ«
        await hands.send({ image: video });
      }

      // å€’è®¡æ—¶é€»è¾‘
      if (currentState === CaptureState.COUNTDOWN) {
        if (lastBodyRectRef.current) {
          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 2;
          ctx.strokeRect(
            lastBodyRectRef.current.x,
            lastBodyRectRef.current.y,
            lastBodyRectRef.current.width,
            lastBodyRectRef.current.height
          );
        }

        ctx.fillStyle = "#FFD700";
        ctx.strokeStyle = "#000000";
        ctx.lineWidth = 5;
        ctx.font = "bold 120px Arial";
        const text = countdownRef.current.toString();
        const textWidth = ctx.measureText(text).width;
        const x = (canvas.width - textWidth) / 2;
        const y = canvas.height / 2;
        ctx.strokeText(text, x, y);
        ctx.fillText(text, x, y);
      }

      // ç»˜åˆ¶çŠ¶æ€æ¶ˆæ¯
      const currentStatusMessage = statusMessageRef.current;
      if (currentStatusMessage && currentState !== CaptureState.COUNTDOWN) {
        ctx.fillStyle = "#FFFFFF";
        ctx.strokeStyle = "#000000";
        ctx.lineWidth = 3;
        ctx.font = "bold 32px Arial";
        const textWidth = ctx.measureText(currentStatusMessage).width;
        const x = (canvas.width - textWidth) / 2;
        const y = canvas.height - 50;
        ctx.strokeText(currentStatusMessage, x, y);
        ctx.fillText(currentStatusMessage, x, y);
      }
    } catch (err) {
      console.error("Frame processing error:", err);
    } finally {
      processingRef.current = false;
    }
  }, [detectFullBody]);

  // MediaPipe æ‰‹åŠ¿è¯†åˆ«ç»“æœå¤„ç†
  const onHandsResults = React.useCallback((results: Results) => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    if (!canvas || !video) return;

    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    const currentTime = Date.now();
    const currentState = stateRef.current;

    // ç»˜åˆ¶åŸºç¡€ç”»é¢
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

    let isOKDetected = false;

    // ç»˜åˆ¶æ‰‹éƒ¨æ£€æµ‹
    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
      for (const landmarks of results.multiHandLandmarks) {
        drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
          color: "#00FF00",
          lineWidth: 3,
        });
        drawLandmarks(ctx, landmarks, {
          color: "#FF0000",
          lineWidth: 1,
          radius: 4,
        });

        if (recognizeOKGesture(landmarks)) {
          isOKDetected = true;

          ctx.font = "bold 48px Arial";
          ctx.fillStyle = "#00FF00";
          ctx.strokeStyle = "#000000";
          ctx.lineWidth = 3;
          const text = "OK ğŸ‘Œ";
          const textWidth = ctx.measureText(text).width;
          const x = (canvas.width - textWidth) / 2;
          const y = 80;
          ctx.strokeText(text, x, y);
          ctx.fillText(text, x, y);
        }
      }
    }

    // æ‰‹åŠ¿çŠ¶æ€ç®¡ç†
    if (isOKDetected) {
      if (currentState === CaptureState.DETECTING_GESTURE) {
        gestureDetectionStartTime.current = currentTime;
        setState(CaptureState.GESTURE_DETECTED);
      } else if (
        currentState === CaptureState.GESTURE_DETECTED &&
        gestureDetectionStartTime.current
      ) {
        const elapsed = currentTime - gestureDetectionStartTime.current;
        const remaining = Math.ceil((3000 - elapsed) / 1000);

        if (elapsed >= 3000) {
          setState(CaptureState.COUNTDOWN);
          setCountdown(5);
          setStatusMessage("å‡†å¤‡æ‹ç…§ï¼");
        } else {
          setStatusMessage(`ä¿æŒOKæ‰‹åŠ¿ ${remaining}s`);
        }
      }
    } else {
      if (currentState === CaptureState.GESTURE_DETECTED) {
        setState(CaptureState.DETECTING_GESTURE);
        gestureDetectionStartTime.current = null;
        setStatusMessage("è¯·åšå‡ºOKæ‰‹åŠ¿");
      }
    }

    // ç»˜åˆ¶å…¨èº«æ¡†
    if (lastBodyRectRef.current) {
      ctx.strokeStyle = "#00FF00";
      ctx.lineWidth = 2;
      ctx.strokeRect(
        lastBodyRectRef.current.x,
        lastBodyRectRef.current.y,
        lastBodyRectRef.current.width,
        lastBodyRectRef.current.height
      );
    }

    const currentStatusMessage = statusMessageRef.current;
    if (currentStatusMessage) {
      ctx.fillStyle = "#FFFFFF";
      ctx.strokeStyle = "#000000";
      ctx.lineWidth = 3;
      ctx.font = "bold 32px Arial";
      const textWidth = ctx.measureText(currentStatusMessage).width;
      const x = (canvas.width - textWidth) / 2;
      const y = canvas.height - 50;
      ctx.strokeText(currentStatusMessage, x, y);
      ctx.fillText(currentStatusMessage, x, y);
    }
  }, []);

  // å€’è®¡æ—¶æ•ˆæœ
  React.useEffect(() => {
    if (state === CaptureState.COUNTDOWN) {
      if (countdown > 0) {
        const timer = setTimeout(() => {
          setCountdown(countdown - 1);
        }, 1000);
        return () => clearTimeout(timer);
      } else {
        setState(CaptureState.CAPTURE);
      }
    }
  }, [state, countdown]);

  // æ‹ç…§å¤„ç†
  React.useEffect(() => {
    if (state === CaptureState.CAPTURE) {
      const video = videoRef.current;
      const capturedCanvas = capturedImageRef.current;

      if (video && capturedCanvas && lastBodyRectRef.current) {
        const capturedCtx = capturedCanvas.getContext("2d");

        if (capturedCtx) {
          const tempCanvas = document.createElement("canvas");
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;
          const tempCtx = tempCanvas.getContext("2d");

          if (tempCtx) {
            tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

            const canvas = canvasRef.current;
            if (canvas) {
              const scaleX = video.videoWidth / canvas.width;
              const scaleY = video.videoHeight / canvas.height;

              const rect = lastBodyRectRef.current;
              const padding = 20;

              const x = Math.max(0, (rect.x - padding) * scaleX);
              const y = Math.max(0, (rect.y - padding) * scaleY);
              const width = Math.min(
                video.videoWidth - x,
                (rect.width + padding * 2) * scaleX
              );
              const height = Math.min(
                video.videoHeight - y,
                (rect.height + padding * 2) * scaleY
              );

              capturedCanvas.width = width * 1.5;
              capturedCanvas.height = height * 1.5;

              capturedCtx.drawImage(
                tempCanvas,
                x,
                y,
                width,
                height,
                0,
                0,
                capturedCanvas.width,
                capturedCanvas.height
              );
            }
          }

          // æš‚åœè§†é¢‘
          video.pause();
          setState(CaptureState.COMPLETED);
          setStatusMessage("âœ“ æ‹ç…§å®Œæˆï¼");
        }
      }
    }
  }, [state]);

  // è§†é¢‘å¸§å¾ªç¯
  React.useEffect(() => {
    if (
      state !== CaptureState.IDLE &&
      state !== CaptureState.COMPLETED &&
      videoRef.current
    ) {
      console.log("å¯åŠ¨è§†é¢‘å¸§å¾ªç¯ï¼Œå½“å‰çŠ¶æ€:", state);

      const loop = () => {
        processFrame();
        animationFrameRef.current = requestAnimationFrame(loop);
      };
      loop();

      return () => {
        console.log("åœæ­¢è§†é¢‘å¸§å¾ªç¯");
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
        }
      };
    } else {
      console.log("å¸§å¾ªç¯æœªå¯åŠ¨ï¼Œå½“å‰çŠ¶æ€:", state);
    }
  }, [state, processFrame]);

  // æ£€æŸ¥å…ƒç´ æ˜¯å¦å·²æŒ‚è½½
  React.useEffect(() => {
    console.log("=== æ£€æŸ¥é¡µé¢å…ƒç´  ===");
    console.log("videoRef:", videoRef.current);
    console.log("canvasRef:", canvasRef.current);
    console.log("capturedImageRef:", capturedImageRef.current);
  }, []);

  // åˆå§‹åŒ–
  React.useEffect(() => {
    console.log("=== å¼€å§‹åˆå§‹åŒ–ç»„ä»¶ ===");
    let mounted = true;
    let hands: Hands | null = null;

    const initialize = async () => {
      try {
        console.log("1. å¼€å§‹åŠ è½½å…¨èº«æ£€æµ‹æ¨¡å‹...");
        await loadFullBodyModels();
        console.log("âœ“ å…¨èº«æ£€æµ‹æ¨¡å‹åŠ è½½å®Œæˆ");

        if (!mounted) {
          console.log("ç»„ä»¶å·²å¸è½½ï¼Œåœæ­¢åˆå§‹åŒ–");
          return;
        }

        console.log("2. è·å–å…¨èº«æ£€æµ‹åˆ†ç±»å™¨...");
        fullBodyCascadeRef.current = getFullBodyCascade();
        console.log("âœ“ åˆ†ç±»å™¨è·å–æˆåŠŸ");

        console.log("3. åˆå§‹åŒ– MediaPipe Hands...");
        hands = new Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
          },
        });

        hands.setOptions({
          maxNumHands: 2,
          modelComplexity: 1,
          minDetectionConfidence: 0.7,
          minTrackingConfidence: 0.5,
        });

        hands.onResults(onHandsResults);
        handsRef.current = hands;
        console.log("âœ“ MediaPipe Hands åˆå§‹åŒ–å®Œæˆ");

        setIsLoading(false);
        console.log("=== åˆå§‹åŒ–å®Œæˆï¼Œå¯ä»¥ä¸Šä¼ è§†é¢‘äº† ===");

        // å†æ¬¡æ£€æŸ¥å…ƒç´ 
        console.log(
          "æœ€ç»ˆæ£€æŸ¥ - videoRef:",
          !!videoRef.current,
          "canvasRef:",
          !!canvasRef.current
        );
      } catch (err) {
        console.error("âŒ åˆå§‹åŒ–å¤±è´¥:", err);
        if (mounted) {
          setError("æ— æ³•åŠ è½½æ¨¡å‹");
          setIsLoading(false);
        }
      }
    };

    initialize();

    return () => {
      console.log("=== æ¸…ç†ç»„ä»¶ ===");
      mounted = false;
      if (hands) {
        try {
          hands.close();
        } catch (err) {
          console.error("Hands cleanup error:", err);
        }
      }
      handsRef.current = null;
    };
  }, [onHandsResults]);

  // å¤„ç†è§†é¢‘ä¸Šä¼ 
  const handleVideoUpload = async (
    event: React.ChangeEvent<HTMLInputElement>
  ) => {
    console.log("=== å¼€å§‹å¤„ç†è§†é¢‘ä¸Šä¼  ===");
    const file = event.target.files?.[0];
    if (!file) {
      console.log("æœªé€‰æ‹©æ–‡ä»¶");
      return;
    }

    console.log("æ–‡ä»¶ä¿¡æ¯:", {
      name: file.name,
      type: file.type,
      size: file.size,
    });

    if (!file.type.startsWith("video/")) {
      setError("è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶");
      return;
    }

    setVideoFile(file);
    setError(null);
    setStatusMessage("æ­£åœ¨åŠ è½½è§†é¢‘...");

    const video = videoRef.current;
    const canvas = canvasRef.current;

    console.log("æ£€æŸ¥å…ƒç´ :", {
      video: !!video,
      canvas: !!canvas,
      hands: !!handsRef.current,
    });

    if (!video || !canvas) {
      console.error("âŒ è§†é¢‘æˆ–ç”»å¸ƒå…ƒç´ æœªæ‰¾åˆ°");
      setError("é¡µé¢å…ƒç´ æœªå‡†å¤‡å¥½ï¼Œè¯·åˆ·æ–°é¡µé¢");
      return;
    }

    console.log("âœ“ è§†é¢‘å’Œç”»å¸ƒå…ƒç´ å·²å‡†å¤‡å¥½");

    const url = URL.createObjectURL(file);
    console.log("åˆ›å»ºè§†é¢‘URL:", url);
    video.src = url;

    video.onloadedmetadata = async () => {
      try {
        console.log(
          "âœ“ è§†é¢‘å…ƒæ•°æ®åŠ è½½å®Œæˆ:",
          video.videoWidth,
          "x",
          video.videoHeight
        );

        // è®¾ç½® canvas å°ºå¯¸
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        console.log("âœ“ Canvas å°ºå¯¸å·²è®¾ç½®");

        // æ·»åŠ æ’­æ”¾äº‹ä»¶ç›‘å¬
        video.onplay = () => {
          console.log("ğŸ¬ è§†é¢‘å¼€å§‹æ’­æ”¾");
          setIsVideoPlaying(true);
        };

        video.onpause = () => {
          console.log("â¸ï¸ è§†é¢‘æš‚åœ");
          setIsVideoPlaying(false);
        };

        // å°è¯•æ’­æ”¾è§†é¢‘
        console.log("å°è¯•æ’­æ”¾è§†é¢‘...");
        await video.play();
        console.log("âœ“ è§†é¢‘æ’­æ”¾æˆåŠŸ");

        console.log("ğŸ“ è®¾ç½®çŠ¶æ€ä¸º VIDEO_LOADED");
        setState(CaptureState.VIDEO_LOADED);
        setStatusMessage("è§†é¢‘å·²åŠ è½½ï¼Œç­‰å¾…æ£€æµ‹...");

        // ç¡®ä¿è§†é¢‘æ­£åœ¨æ’­æ”¾
        setTimeout(() => {
          if (video.paused) {
            console.warn("âš ï¸ è§†é¢‘æœªæ’­æ”¾ï¼Œå°è¯•æ‰‹åŠ¨æ’­æ”¾");
            video.play().catch((e) => console.error("æ‰‹åŠ¨æ’­æ”¾å¤±è´¥:", e));
          } else {
            console.log("âœ“ è§†é¢‘æ­£åœ¨æ’­æ”¾ï¼Œå‡†å¤‡å¼€å§‹æ£€æµ‹");
          }
        }, 100);
      } catch (err) {
        console.error("âŒ è§†é¢‘æ’­æ”¾å¤±è´¥:", err);
        setError("è§†é¢‘æ’­æ”¾å¤±è´¥ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹æ’­æ”¾æŒ‰é’®");
        setIsVideoPlaying(false);
      }
    };

    video.onerror = (e) => {
      console.error("âŒ è§†é¢‘åŠ è½½é”™è¯¯:", e);
      setError("è§†é¢‘åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼");
    };
  };

  const handleReset = () => {
    setState(CaptureState.IDLE);
    setStatusMessage("");
    setCountdown(5);
    setVideoFile(null);
    setIsVideoPlaying(false);
    bodyDetectionStartTime.current = null;
    lastBodyDetectedTime.current = null;
    gestureDetectionStartTime.current = null;
    lastBodyRectRef.current = null;
    frameCountRef.current = 0;

    if (videoRef.current) {
      videoRef.current.pause();
      videoRef.current.src = "";
      videoRef.current.load();
    }

    if (capturedImageRef.current) {
      const ctx = capturedImageRef.current.getContext("2d");
      if (ctx) {
        ctx.clearRect(
          0,
          0,
          capturedImageRef.current.width,
          capturedImageRef.current.height
        );
      }
    }

    if (fileInputRef.current) {
      fileInputRef.current.value = "";
    }
  };

  const handleDownload = () => {
    if (capturedImageRef.current && state === CaptureState.COMPLETED) {
      const link = document.createElement("a");
      link.download = `photo_${Date.now()}.png`;
      link.href = capturedImageRef.current.toDataURL();
      link.click();
    }
  };

  return (
    <div className="integrated-capture-container">
      <h2>ğŸ¬ æ™ºèƒ½è§†é¢‘æ‹ç…§ç³»ç»Ÿ</h2>

      {isLoading && <div className="loading">â³ æ­£åœ¨åŠ è½½æ¨¡å‹...</div>}

      {error && (
        <div className="error-message">
          <p>âŒ {error}</p>
        </div>
      )}

      {state === CaptureState.IDLE && !isLoading && (
        <div className="upload-section">
          <input
            ref={fileInputRef}
            type="file"
            accept="video/*"
            onChange={handleVideoUpload}
            style={{ display: "none" }}
          />
          <button
            className="upload-btn"
            onClick={() => {
              console.log("=== ç‚¹å‡»ä¸Šä¼ æŒ‰é’® ===");
              console.log("fileInputRef:", fileInputRef.current);
              console.log("isLoading:", isLoading);
              console.log("state:", state);
              fileInputRef.current?.click();
            }}
            disabled={isLoading}
          >
            ğŸ“‚ ä¸Šä¼ è§†é¢‘
          </button>
          <p className="upload-hint">æ”¯æŒ MP4, MOV, AVI ç­‰è§†é¢‘æ ¼å¼</p>
          <p className="upload-note">ğŸ’¡ æç¤ºï¼šè§†é¢‘ä¸Šä¼ åä¼šè‡ªåŠ¨å¼€å§‹æ’­æ”¾å’Œæ£€æµ‹</p>
        </div>
      )}

      {state === CaptureState.IDLE && isLoading && (
        <div className="upload-section">
          <p>â³ æ­£åœ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...</p>
        </div>
      )}

      {/* è§†é¢‘å’Œç”»å¸ƒå…ƒç´ å§‹ç»ˆå­˜åœ¨ï¼Œä½†åœ¨ IDLE æ—¶éšè— */}
      <div
        className="capture-content"
        style={{ display: state === CaptureState.IDLE ? "none" : "block" }}
      >
        <div className="video-container">
          <video
            ref={videoRef}
            style={{ display: "none" }}
            playsInline
            muted
            loop
          />
          <canvas
            ref={canvasRef}
            className="capture-canvas"
            onClick={() => {
              const video = videoRef.current;
              if (video && video.paused) {
                video.play().catch((err) => {
                  console.error("æ‰‹åŠ¨æ’­æ”¾å¤±è´¥:", err);
                });
              }
            }}
            style={{ cursor: "pointer" }}
          />
        </div>

        {state !== CaptureState.COMPLETED && videoFile && (
          <div className="video-controls">
            <button
              onClick={() => {
                const video = videoRef.current;
                if (video) {
                  if (video.paused) {
                    video.play().catch((err) => {
                      console.error("æ’­æ”¾å¤±è´¥:", err);
                      setError("è§†é¢‘æ’­æ”¾å¤±è´¥");
                    });
                  } else {
                    video.pause();
                  }
                }
              }}
              className="control-btn"
            >
              {isVideoPlaying ? "â¸ï¸ æš‚åœ" : "â–¶ï¸ æ’­æ”¾"}
            </button>
            <button
              onClick={() => {
                const video = videoRef.current;
                if (video) {
                  video.currentTime = 0;
                  video.play().catch((err) => {
                    console.error("é‡æ’­å¤±è´¥:", err);
                  });
                }
              }}
              className="control-btn"
            >
              ğŸ”„ é‡æ’­
            </button>
          </div>
        )}

        {state === CaptureState.COMPLETED && (
          <div className="captured-image-container">
            <h3>ğŸ“· æ•è·çš„ç…§ç‰‡</h3>
            <canvas ref={capturedImageRef} className="captured-image" />
            <div className="capture-actions">
              <button onClick={handleDownload} className="download-btn">
                â¬‡ï¸ ä¸‹è½½ç…§ç‰‡
              </button>
              <button onClick={handleReset} className="reset-btn">
                ğŸ”„ é‡æ–°ä¸Šä¼ 
              </button>
            </div>
          </div>
        )}
      </div>

      {state !== CaptureState.IDLE && (
        <div className="status-panel">
          <h3>ğŸ“Š çŠ¶æ€ä¿¡æ¯</h3>
          <div className="status-item">
            <span className="status-label">è§†é¢‘æ–‡ä»¶ï¼š</span>
            <span className="status-value">{videoFile?.name || "æ— "}</span>
          </div>
          <div className="status-item">
            <span className="status-label">æ’­æ”¾çŠ¶æ€ï¼š</span>
            <span className="status-value">
              {isVideoPlaying ? "â–¶ï¸ æ’­æ”¾ä¸­" : "â¸ï¸ å·²æš‚åœ"}
            </span>
          </div>
          <div className="status-item">
            <span className="status-label">å½“å‰é˜¶æ®µï¼š</span>
            <span className={`status-value state-${state}`}>
              {state === CaptureState.VIDEO_LOADED && "è§†é¢‘å·²åŠ è½½"}
              {state === CaptureState.DETECTING_BODY && "æ£€æµ‹å…¨èº«ä¸­"}
              {state === CaptureState.BODY_DETECTED && "å·²è¯†åˆ«å…¨èº«"}
              {state === CaptureState.DETECTING_GESTURE && "ç­‰å¾…æ‰‹åŠ¿"}
              {state === CaptureState.GESTURE_DETECTED && "æ£€æµ‹åˆ°OKæ‰‹åŠ¿"}
              {state === CaptureState.COUNTDOWN && "å€’è®¡æ—¶ä¸­"}
              {state === CaptureState.CAPTURE && "æ­£åœ¨æ‹ç…§"}
              {state === CaptureState.COMPLETED && "æ‹ç…§å®Œæˆ"}
            </span>
          </div>
          {statusMessage && (
            <div className="status-item">
              <span className="status-label">æç¤ºï¼š</span>
              <span className="status-value">{statusMessage}</span>
            </div>
          )}
        </div>
      )}

      {state !== CaptureState.IDLE && state !== CaptureState.COMPLETED && (
        <div className="instructions">
          <h3>ğŸ“ ä½¿ç”¨æµç¨‹</h3>
          <div className="instruction-steps">
            <div
              className={`step ${
                state === CaptureState.DETECTING_BODY ||
                state === CaptureState.BODY_DETECTED
                  ? "active"
                  : ""
              } ${
                state !== CaptureState.VIDEO_LOADED &&
                state !== CaptureState.DETECTING_BODY &&
                state !== CaptureState.BODY_DETECTED
                  ? "completed"
                  : ""
              }`}
            >
              <span className="step-number">1</span>
              <div className="step-content">
                <h4>å…¨èº«è¯†åˆ«</h4>
                <p>è§†é¢‘æ’­æ”¾æ—¶è‡ªåŠ¨æ£€æµ‹å…¨èº«ï¼ŒæŒç»­1ç§’</p>
                <p className="step-note">
                  ğŸ’¡ æ”¯æŒå¤šäººæ£€æµ‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æœ€å¤§çš„ç›®æ ‡
                </p>
              </div>
            </div>

            <div
              className={[
                "step",
                state === "detecting_gesture" || state === "gesture_detected"
                  ? "active"
                  : "",
                state === "countdown" || state === "capture" ? "completed" : "",
              ]
                .filter(Boolean)
                .join(" ")}
            >
              <span className="step-number">2</span>
              <div className="step-content">
                <h4>OKæ‰‹åŠ¿</h4>
                <p>è§†é¢‘ä¸­å‡ºç°OKæ‰‹åŠ¿å¹¶ä¿æŒ3ç§’</p>
              </div>
            </div>

            <div
              className={[
                "step",
                state === "countdown" ? "active" : "",
                state === "capture" ? "completed" : "",
              ]
                .filter(Boolean)
                .join(" ")}
            >
              <span className="step-number">3</span>
              <div className="step-content">
                <h4>å€’è®¡æ—¶æ‹ç…§</h4>
                <p>5ç§’å€’è®¡æ—¶åè‡ªåŠ¨æ‹ç…§</p>
              </div>
            </div>
          </div>
        </div>
      )}

      {state !== CaptureState.IDLE && state !== CaptureState.COMPLETED && (
        <button onClick={handleReset} className="cancel-btn">
          âŒ å–æ¶ˆå¹¶é‡æ–°å¼€å§‹
        </button>
      )}
    </div>
  );
}
