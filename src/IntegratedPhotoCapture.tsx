import React from "react";
import cv from "@techstark/opencv-js";
import {
  Hands,
  HAND_CONNECTIONS,
  type Results,
  type NormalizedLandmark,
} from "@mediapipe/hands";
import { Camera } from "@mediapipe/camera_utils";
import { drawConnectors, drawLandmarks } from "@mediapipe/drawing_utils";
import { loadFullBodyModels, getFullBodyCascade } from "./fullBodyDetection";
import type { CascadeClassifier } from "@techstark/opencv-js";

// çŠ¶æ€æšä¸¾
const CaptureState = {
  IDLE: "idle",
  DETECTING_BODY: "detecting_body",
  BODY_DETECTED: "body_detected",
  DETECTING_GESTURE: "detecting_gesture",
  GESTURE_DETECTED: "gesture_detected",
  COUNTDOWN: "countdown",
  CAPTURE: "capture",
  COMPLETED: "completed",
} as const;

type CaptureState = (typeof CaptureState)[keyof typeof CaptureState];

interface BodyRect {
  x: number;
  y: number;
  width: number;
  height: number;
}

// è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»
function calculateDistance(
  point1: NormalizedLandmark,
  point2: NormalizedLandmark
): number {
  const dx = point1.x - point2.x;
  const dy = point1.y - point2.y;
  const dz = point1.z - point2.z;
  return Math.sqrt(dx * dx + dy * dy + dz * dz);
}

// è¯†åˆ«OKæ‰‹åŠ¿
function recognizeOKGesture(landmarks: NormalizedLandmark[]): boolean {
  const thumbTip = landmarks[4];
  const indexTip = landmarks[8];
  const indexPip = landmarks[6];
  const middleTip = landmarks[12];
  const ringTip = landmarks[16];
  const pinkyTip = landmarks[20];
  const palmBase = landmarks[9];

  // æ£€æŸ¥å¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡æ˜¯å¦å½¢æˆåœ†åœˆ
  const thumbIndexDist = calculateDistance(thumbTip, indexTip);
  const isCircleFormed = thumbIndexDist < 0.08;

  // æ£€æŸ¥å…¶ä»–ä¸‰æ ¹æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´
  const middleExtended = middleTip.y < palmBase.y - 0.1;
  const ringExtended = ringTip.y < palmBase.y - 0.08;
  const pinkyExtended = pinkyTip.y < palmBase.y - 0.06;

  // ç¡®ä¿é£ŸæŒ‡æ˜¯å¼¯æ›²çš„
  const indexBent = indexPip.y < indexTip.y;

  return (
    isCircleFormed &&
    middleExtended &&
    ringExtended &&
    pinkyExtended &&
    indexBent
  );
}

export default function IntegratedPhotoCapture(): React.JSX.Element {
  const videoRef = React.useRef<HTMLVideoElement>(null);
  const canvasRef = React.useRef<HTMLCanvasElement>(null);
  const capturedImageRef = React.useRef<HTMLCanvasElement>(null);

  const [state, setState] = React.useState<CaptureState>(CaptureState.IDLE);
  const [isLoading, setIsLoading] = React.useState<boolean>(true);
  const [error, setError] = React.useState<string | null>(null);
  const [statusMessage, setStatusMessage] = React.useState<string>("");
  const [countdown, setCountdown] = React.useState<number>(5);

  // æ—¶é—´è¿½è¸ª
  const bodyDetectionStartTime = React.useRef<number | null>(null);
  const lastBodyDetectedTime = React.useRef<number | null>(null);
  const gestureDetectionStartTime = React.useRef<number | null>(null);

  // å…¨èº«æ£€æµ‹ç›¸å…³
  const fullBodyCascadeRef = React.useRef<CascadeClassifier | null>(null);
  const lastBodyRectRef = React.useRef<BodyRect | null>(null);

  // MediaPipe Hands
  const handsRef = React.useRef<Hands | null>(null);
  const cameraRef = React.useRef<Camera | null>(null);

  // æ€§èƒ½ä¼˜åŒ–ï¼šå¸§è®¡æ•°å™¨
  const frameCountRef = React.useRef<number>(0);

  // ä½¿ç”¨ ref å­˜å‚¨æœ€æ–°çš„çŠ¶æ€ï¼Œé¿å…å›è°ƒå‡½æ•°é‡æ–°åˆ›å»º
  const stateRef = React.useRef(state);
  const countdownRef = React.useRef(countdown);
  const statusMessageRef = React.useRef(statusMessage);

  // åŒæ­¥ ref å€¼
  React.useEffect(() => {
    stateRef.current = state;
    countdownRef.current = countdown;
    statusMessageRef.current = statusMessage;
  }, [state, countdown, statusMessage]);

  // æ£€æµ‹å…¨èº«ï¼ˆæ”¯æŒå¤šäººï¼Œé€‰æ‹©æœ€å¤§è€…ï¼‰
  const detectFullBody = React.useCallback(
    (
      imageData: ImageData
    ): { count: number; rect: BodyRect | null; allRects: BodyRect[] } => {
      if (!fullBodyCascadeRef.current) {
        return { count: 0, rect: null, allRects: [] };
      }

      try {
        // åˆ›å»º Mat ä» ImageData
        const src = cv.matFromImageData(imageData);

        // è½¬æ¢ä¸ºç°åº¦å›¾
        const gray = new cv.Mat();
        cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);

        const bodies = new cv.RectVector();
        const msize = new cv.Size(0, 0);

        // ä½¿ç”¨åŸå§‹å°ºå¯¸è¿›è¡Œæ£€æµ‹ï¼Œæé«˜å‡†ç¡®åº¦
        fullBodyCascadeRef.current.detectMultiScale(
          gray,
          bodies,
          1.1,
          5,
          0,
          new cv.Size(50, 100), // åŸå§‹å°ºå¯¸çš„æœ€å°æ£€æµ‹åŒºåŸŸ
          msize
        );

        const count = bodies.size();
        const allRects: BodyRect[] = [];
        let largestRect: BodyRect | null = null;
        let largestArea = 0;

        // æ”¶é›†æ‰€æœ‰æ£€æµ‹åˆ°çš„èº«ä½“ï¼Œæ‰¾å‡ºé¢ç§¯æœ€å¤§çš„
        for (let i = 0; i < count; ++i) {
          const body = bodies.get(i);
          const rect = {
            x: body.x,
            y: body.y,
            width: body.width,
            height: body.height,
          };
          allRects.push(rect);

          const area = rect.width * rect.height;
          if (area > largestArea) {
            largestArea = area;
            largestRect = rect;
          }
        }

        gray.delete();
        src.delete();
        bodies.delete();

        return { count, rect: largestRect, allRects };
      } catch (err) {
        console.error("å…¨èº«æ£€æµ‹é”™è¯¯:", err);
        return { count: 0, rect: null, allRects: [] };
      }
    },
    []
  );

  // ç»˜åˆ¶è§†é¢‘å¸§å’Œæç¤ºä¿¡æ¯ï¼ˆä¸ä¾èµ–ä»»ä½•çŠ¶æ€ï¼‰
  const drawFrame = React.useCallback(
    (
      videoElement: HTMLVideoElement,
      canvas: HTMLCanvasElement,
      largestRect?: BodyRect | null,
      allRects?: BodyRect[],
      bodyCount?: number
    ) => {
      const ctx = canvas.getContext("2d");
      if (!ctx) return;

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);

      // ç»˜åˆ¶æ‰€æœ‰æ£€æµ‹åˆ°çš„èº«ä½“æ¡†
      if (allRects && allRects.length > 0) {
        allRects.forEach((rect, index) => {
          const isLargest =
            largestRect &&
            rect.x === largestRect.x &&
            rect.y === largestRect.y &&
            rect.width === largestRect.width &&
            rect.height === largestRect.height;

          // æœ€å¤§çš„ç”¨ç»¿è‰²ç²—æ¡†ï¼Œå…¶ä»–ç”¨é»„è‰²ç»†æ¡†
          ctx.strokeStyle = isLargest ? "#00FF00" : "#FFFF00";
          ctx.lineWidth = isLargest ? 4 : 2;
          ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);

          // æ·»åŠ æ ‡ç­¾
          ctx.fillStyle = isLargest ? "#00FF00" : "#FFFF00";
          ctx.font = "bold 18px Arial";
          const label = isLargest ? `ä¸»ç›®æ ‡ (${index + 1})` : `${index + 1}`;
          ctx.fillText(label, rect.x, rect.y - 10);
        });
      }

      // ç»˜åˆ¶äººæ•°æç¤º
      if (bodyCount !== undefined && bodyCount > 0) {
        const text =
          bodyCount === 1
            ? "æ£€æµ‹åˆ° 1 äºº"
            : `æ£€æµ‹åˆ° ${bodyCount} äººï¼ˆå·²é€‰æ‹©æœ€å¤§è€…ï¼‰`;
        ctx.fillStyle = "#00FF00";
        ctx.font = "bold 24px Arial";
        ctx.fillText(text, 10, 40);
      }

      // ç»˜åˆ¶çŠ¶æ€æ¶ˆæ¯ï¼ˆä½¿ç”¨ refï¼‰
      const currentStatusMessage = statusMessageRef.current;
      if (currentStatusMessage) {
        ctx.fillStyle = "#FFFFFF";
        ctx.strokeStyle = "#000000";
        ctx.lineWidth = 3;
        ctx.font = "bold 32px Arial";
        const textWidth = ctx.measureText(currentStatusMessage).width;
        const x = (canvas.width - textWidth) / 2;
        const y = canvas.height - 50;
        ctx.strokeText(currentStatusMessage, x, y);
        ctx.fillText(currentStatusMessage, x, y);
      }

      // ç»˜åˆ¶å€’è®¡æ—¶ï¼ˆä½¿ç”¨ refï¼‰
      const currentState = stateRef.current;
      const currentCountdown = countdownRef.current;
      if (currentState === CaptureState.COUNTDOWN) {
        ctx.fillStyle = "#FFD700";
        ctx.strokeStyle = "#000000";
        ctx.lineWidth = 5;
        ctx.font = "bold 120px Arial";
        const text = currentCountdown.toString();
        const textWidth = ctx.measureText(text).width;
        const x = (canvas.width - textWidth) / 2;
        const y = canvas.height / 2;
        ctx.strokeText(text, x, y);
        ctx.fillText(text, x, y);
      }
    },
    [] // ä¸ä¾èµ–ä»»ä½•çŠ¶æ€
  );

  // MediaPipe æ‰‹åŠ¿è¯†åˆ«ç»“æœå¤„ç†
  const onHandsResults = React.useCallback(
    (results: Results) => {
      const canvas = canvasRef.current;
      const video = videoRef.current;
      if (!canvas || !video) return;

      // ä½¿ç”¨ willReadFrequently ä¼˜åŒ–æ€§èƒ½
      const ctx = canvas.getContext("2d", { willReadFrequently: true });
      if (!ctx) return;

      // å…ˆç»˜åˆ¶å›¾åƒ
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

      const currentTime = Date.now();
      const currentState = stateRef.current; // ä½¿ç”¨ ref è·å–æœ€æ–°çŠ¶æ€

      // å…¨èº«æ£€æµ‹é€»è¾‘
      if (
        currentState === CaptureState.IDLE ||
        currentState === CaptureState.DETECTING_BODY ||
        currentState === CaptureState.BODY_DETECTED
      ) {
        // åªåœ¨éœ€è¦æ—¶è·å– ImageData
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const { count, rect, allRects } = detectFullBody(imageData);

        if (count >= 1 && rect) {
          // æ£€æµ‹åˆ°è‡³å°‘ä¸€äººï¼Œé€‰æ‹©æœ€å¤§çš„
          lastBodyDetectedTime.current = currentTime;
          lastBodyRectRef.current = rect;

          if (currentState === CaptureState.IDLE) {
            // å¼€å§‹æ£€æµ‹å…¨èº«
            setState(CaptureState.DETECTING_BODY);
            bodyDetectionStartTime.current = currentTime;
            setStatusMessage("æ­£åœ¨æ£€æµ‹å…¨èº«...");
          } else if (currentState === CaptureState.DETECTING_BODY) {
            // æ£€æŸ¥æ˜¯å¦æŒç»­1ç§’
            if (
              bodyDetectionStartTime.current &&
              currentTime - bodyDetectionStartTime.current >= 1000
            ) {
              setState(CaptureState.BODY_DETECTED);
              setStatusMessage("âœ“ å·²è¯†åˆ«åˆ°å…¨èº«");
              // å»¶è¿Ÿè¿›å…¥æ‰‹åŠ¿è¯†åˆ«æ¨¡å¼
              setTimeout(() => {
                setState(CaptureState.DETECTING_GESTURE);
                setStatusMessage("è¯·åšå‡ºOKæ‰‹åŠ¿");
              }, 1500);
            } else {
              setStatusMessage("æ­£åœ¨æ£€æµ‹å…¨èº«...");
            }
          } else if (currentState === CaptureState.BODY_DETECTED) {
            setStatusMessage("âœ“ å·²è¯†åˆ«åˆ°å…¨èº«");
          }

          drawFrame(video, canvas, rect, allRects, count);
        } else {
          // æœªæ£€æµ‹åˆ°ä»»ä½•äºº
          if (
            currentState === CaptureState.DETECTING_BODY ||
            currentState === CaptureState.BODY_DETECTED
          ) {
            // æ£€æŸ¥æ˜¯å¦è¶…è¿‡1ç§’æœªæ£€æµ‹åˆ°
            if (
              lastBodyDetectedTime.current &&
              currentTime - lastBodyDetectedTime.current >= 1000
            ) {
              // é‡æ–°å¼€å§‹
              setState(CaptureState.IDLE);
              bodyDetectionStartTime.current = null;
              lastBodyDetectedTime.current = null;
              setStatusMessage("âŒ æœªè¯†åˆ«åˆ°å…¨èº«ï¼Œé‡æ–°å¼€å§‹");
              setTimeout(() => setStatusMessage(""), 2000);
            } else {
              setStatusMessage("æ­£åœ¨æ£€æµ‹å…¨èº«...");
            }
          }

          drawFrame(video, canvas, null, allRects, count);
        }
      }

      // æ‰‹åŠ¿æ£€æµ‹é€»è¾‘
      if (
        currentState === CaptureState.DETECTING_GESTURE ||
        currentState === CaptureState.GESTURE_DETECTED
      ) {
        // æ€§èƒ½ä¼˜åŒ–ï¼šé™ä½å…¨èº«æ£€æµ‹é¢‘ç‡ï¼Œæ¯å¸§æ£€æµ‹ä¸€æ¬¡
        frameCountRef.current++;
        if (frameCountRef.current % 1 === 0) {
          // åªåœ¨æ£€æµ‹å¸§è·å– ImageData
          const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
          const { count, rect } = detectFullBody(imageData);
          if (count >= 1 && rect) {
            // æ£€æµ‹åˆ°è‡³å°‘ä¸€äºº
            lastBodyDetectedTime.current = currentTime;
            lastBodyRectRef.current = rect;
          } else if (
            lastBodyDetectedTime.current &&
            currentTime - lastBodyDetectedTime.current >= 1000
          ) {
            // å…¨èº«ä¸¢å¤±è¶…è¿‡1ç§’ï¼Œé‡æ–°å¼€å§‹
            setState(CaptureState.IDLE);
            bodyDetectionStartTime.current = null;
            lastBodyDetectedTime.current = null;
            gestureDetectionStartTime.current = null;
            frameCountRef.current = 0;
            setStatusMessage("âŒ å…¨èº«ä¸¢å¤±ï¼Œé‡æ–°å¼€å§‹");
            setTimeout(() => setStatusMessage(""), 2000);
            return;
          }
        }

        // ç»˜åˆ¶åŸºç¡€ç”»é¢
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

        let isOKDetected = false;

        // ç»˜åˆ¶æ‰‹éƒ¨æ£€æµ‹
        if (
          results.multiHandLandmarks &&
          results.multiHandLandmarks.length > 0
        ) {
          for (const landmarks of results.multiHandLandmarks) {
            drawConnectors(ctx, landmarks, HAND_CONNECTIONS, {
              color: "#00FF00",
              lineWidth: 3,
            });
            drawLandmarks(ctx, landmarks, {
              color: "#FF0000",
              lineWidth: 1,
              radius: 4,
            });

            if (recognizeOKGesture(landmarks)) {
              isOKDetected = true;

              // ç»˜åˆ¶ OK æ ‡è¯†
              ctx.font = "bold 48px Arial";
              ctx.fillStyle = "#00FF00";
              ctx.strokeStyle = "#000000";
              ctx.lineWidth = 3;
              const text = "OK ğŸ‘Œ";
              const textWidth = ctx.measureText(text).width;
              const x = (canvas.width - textWidth) / 2;
              const y = 80;
              ctx.strokeText(text, x, y);
              ctx.fillText(text, x, y);
            }
          }
        }

        // æ‰‹åŠ¿çŠ¶æ€ç®¡ç†
        if (isOKDetected) {
          if (currentState === CaptureState.DETECTING_GESTURE) {
            gestureDetectionStartTime.current = currentTime;
            setState(CaptureState.GESTURE_DETECTED);
          } else if (
            currentState === CaptureState.GESTURE_DETECTED &&
            gestureDetectionStartTime.current
          ) {
            const elapsed = currentTime - gestureDetectionStartTime.current;
            const remaining = Math.ceil((3000 - elapsed) / 1000);

            if (elapsed >= 3000) {
              // è¿›å…¥å€’è®¡æ—¶é˜¶æ®µ
              setState(CaptureState.COUNTDOWN);
              setCountdown(5);
              setStatusMessage("å‡†å¤‡æ‹ç…§ï¼");
            } else {
              setStatusMessage(`ä¿æŒOKæ‰‹åŠ¿ ${remaining}s`);
            }
          }
        } else {
          if (currentState === CaptureState.GESTURE_DETECTED) {
            // æ‰‹åŠ¿ä¸­æ–­ï¼Œé‡æ–°æ£€æµ‹
            setState(CaptureState.DETECTING_GESTURE);
            gestureDetectionStartTime.current = null;
            setStatusMessage("è¯·åšå‡ºOKæ‰‹åŠ¿");
          } else {
            setStatusMessage("è¯·åšå‡ºOKæ‰‹åŠ¿");
          }
        }

        // ç»˜åˆ¶å…¨èº«æ¡†å’ŒçŠ¶æ€æ¶ˆæ¯
        if (lastBodyRectRef.current) {
          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 2;
          ctx.strokeRect(
            lastBodyRectRef.current.x,
            lastBodyRectRef.current.y,
            lastBodyRectRef.current.width,
            lastBodyRectRef.current.height
          );
        }

        const currentStatusMessage = statusMessageRef.current;
        if (currentStatusMessage) {
          ctx.fillStyle = "#FFFFFF";
          ctx.strokeStyle = "#000000";
          ctx.lineWidth = 3;
          ctx.font = "bold 32px Arial";
          const textWidth = ctx.measureText(currentStatusMessage).width;
          const x = (canvas.width - textWidth) / 2;
          const y = canvas.height - 50;
          ctx.strokeText(currentStatusMessage, x, y);
          ctx.fillText(currentStatusMessage, x, y);
        }
      }

      // å€’è®¡æ—¶é€»è¾‘ï¼ˆä¸å†è¿›è¡Œæ£€æµ‹ï¼Œç›´æ¥ç»˜åˆ¶ï¼‰
      if (currentState === CaptureState.COUNTDOWN) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

        // ç»˜åˆ¶å…¨èº«æ¡†
        if (lastBodyRectRef.current) {
          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 2;
          ctx.strokeRect(
            lastBodyRectRef.current.x,
            lastBodyRectRef.current.y,
            lastBodyRectRef.current.width,
            lastBodyRectRef.current.height
          );
        }

        // ç»˜åˆ¶å€’è®¡æ—¶æ•°å­—
        ctx.fillStyle = "#FFD700";
        ctx.strokeStyle = "#000000";
        ctx.lineWidth = 5;
        ctx.font = "bold 120px Arial";
        const text = countdownRef.current.toString();
        const textWidth = ctx.measureText(text).width;
        const x = (canvas.width - textWidth) / 2;
        const y = canvas.height / 2;
        ctx.strokeText(text, x, y);
        ctx.fillText(text, x, y);
      }
    },
    // eslint-disable-next-line react-hooks/exhaustive-deps
    [] // å®Œå…¨ä¸ä¾èµ–ä»»ä½•ä¸œè¥¿ï¼Œç¡®ä¿åªåˆ›å»ºä¸€æ¬¡ï¼Œé¿å… MediaPipe Hands é‡å¤åˆå§‹åŒ–
  );

  // å€’è®¡æ—¶æ•ˆæœ
  React.useEffect(() => {
    if (state === CaptureState.COUNTDOWN) {
      if (countdown > 0) {
        const timer = setTimeout(() => {
          setCountdown(countdown - 1);
        }, 1000);
        return () => clearTimeout(timer);
      } else {
        // å€’è®¡æ—¶ç»“æŸï¼Œæ‹ç…§
        setState(CaptureState.CAPTURE);
      }
    }
  }, [state, countdown]);

  // æ‹ç…§å¤„ç†
  React.useEffect(() => {
    if (state === CaptureState.CAPTURE) {
      const video = videoRef.current;
      const capturedCanvas = capturedImageRef.current;

      if (video && capturedCanvas && lastBodyRectRef.current) {
        const capturedCtx = capturedCanvas.getContext("2d");

        if (capturedCtx) {
          // åˆ›å»ºä¸´æ—¶ç”»å¸ƒç”¨äºä»videoè·å–å®Œæ•´ç”»é¢ï¼ˆæ— ä»»ä½•UIå…ƒç´ ï¼‰
          const tempCanvas = document.createElement("canvas");
          tempCanvas.width = video.videoWidth;
          tempCanvas.height = video.videoHeight;
          const tempCtx = tempCanvas.getContext("2d");

          if (tempCtx) {
            // ä»videoå…ƒç´ ç›´æ¥ç»˜åˆ¶åŸå§‹ç”»é¢ï¼ˆç»å¯¹å¹²å‡€ï¼Œæ— UIï¼‰
            tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);

            // è®¡ç®—å…¨èº«åŒºåŸŸï¼ˆéœ€è¦æ ¹æ®canvasåˆ†è¾¨ç‡è½¬æ¢åˆ°videoåˆ†è¾¨ç‡ï¼‰
            const canvas = canvasRef.current;
            if (canvas) {
              const scaleX = video.videoWidth / canvas.width;
              const scaleY = video.videoHeight / canvas.height;

              const rect = lastBodyRectRef.current;
              const padding = 20;

              // è½¬æ¢åæ ‡åˆ°videoåˆ†è¾¨ç‡
              const x = Math.max(0, (rect.x - padding) * scaleX);
              const y = Math.max(0, (rect.y - padding) * scaleY);
              const width = Math.min(
                video.videoWidth - x,
                (rect.width + padding * 2) * scaleX
              );
              const height = Math.min(
                video.videoHeight - y,
                (rect.height + padding * 2) * scaleY
              );

              // è®¾ç½®æ•è·ç”»å¸ƒå¤§å°
              capturedCanvas.width = width * 1.5;
              capturedCanvas.height = height * 1.5;

              // æˆªå–å¹¶æ”¾å¤§ç»˜åˆ¶
              capturedCtx.drawImage(
                tempCanvas,
                x,
                y,
                width,
                height,
                0,
                0,
                capturedCanvas.width,
                capturedCanvas.height
              );
            }
          }

          setState(CaptureState.COMPLETED);
          setStatusMessage("âœ“ æ‹ç…§å®Œæˆï¼");
        }
      }
    }
  }, [state]);

  // åˆå§‹åŒ–
  React.useEffect(() => {
    let mounted = true;
    let camera: Camera | null = null;
    let hands: Hands | null = null;

    const initialize = async () => {
      try {
        // åŠ è½½å…¨èº«æ£€æµ‹æ¨¡å‹ï¼ˆå¸¦ç¼“å­˜ï¼ŒåªåŠ è½½ä¸€æ¬¡ï¼‰
        await loadFullBodyModels();

        if (!mounted) return;

        // è·å–å·²åŠ è½½çš„åˆ†ç±»å™¨å®ä¾‹ï¼ˆä¸å†é‡å¤åˆ›å»ºï¼‰
        fullBodyCascadeRef.current = getFullBodyCascade();

        // åˆå§‹åŒ– MediaPipe Hands
        if (!videoRef.current || !canvasRef.current || !mounted) return;

        hands = new Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
          },
        });

        hands.setOptions({
          maxNumHands: 2,
          modelComplexity: 1,
          minDetectionConfidence: 0.7,
          minTrackingConfidence: 0.5,
        });

        hands.onResults(onHandsResults);
        handsRef.current = hands;

        if (!mounted) {
          hands.close();
          return;
        }

        camera = new Camera(videoRef.current, {
          onFrame: async () => {
            if (mounted && videoRef.current && handsRef.current) {
              try {
                await handsRef.current.send({ image: videoRef.current });
              } catch (err) {
                // å¿½ç•¥ç»„ä»¶å¸è½½æ—¶çš„é”™è¯¯
                if (mounted) {
                  console.error("Frame processing error:", err);
                }
              }
            }
          },
          width: 640,
          height: 480,
        });

        await camera.start();
        cameraRef.current = camera;

        if (!mounted) {
          camera.stop();
          return;
        }

        setIsLoading(false);
        setState(CaptureState.IDLE);
        setStatusMessage("");
      } catch (err) {
        console.error("åˆå§‹åŒ–å¤±è´¥:", err);
        if (mounted) {
          setError("æ— æ³•å¯åŠ¨æ‘„åƒå¤´æˆ–åŠ è½½æ¨¡å‹");
          setIsLoading(false);
        }
      }
    };

    initialize();

    return () => {
      mounted = false;

      // æ¸…ç† camera
      if (camera) {
        try {
          camera.stop();
        } catch (err) {
          console.error("Camera cleanup error:", err);
        }
      }

      // æ¸…ç† hands
      if (hands) {
        try {
          hands.close();
        } catch (err) {
          console.error("Hands cleanup error:", err);
        }
      }

      // æ¸…ç† refs
      cameraRef.current = null;
      handsRef.current = null;
    };
  }, [onHandsResults]);

  const handleReset = () => {
    setState(CaptureState.IDLE);
    setStatusMessage("");
    setCountdown(5);
    bodyDetectionStartTime.current = null;
    lastBodyDetectedTime.current = null;
    gestureDetectionStartTime.current = null;
    lastBodyRectRef.current = null;
    frameCountRef.current = 0; // é‡ç½®å¸§è®¡æ•°å™¨

    // æ¸…ç©ºæ•è·çš„å›¾åƒ
    if (capturedImageRef.current) {
      const ctx = capturedImageRef.current.getContext("2d");
      if (ctx) {
        ctx.clearRect(
          0,
          0,
          capturedImageRef.current.width,
          capturedImageRef.current.height
        );
      }
    }
  };

  const handleDownload = () => {
    if (capturedImageRef.current && state === CaptureState.COMPLETED) {
      const link = document.createElement("a");
      link.download = `photo_${Date.now()}.png`;
      link.href = capturedImageRef.current.toDataURL();
      link.click();
    }
  };

  return (
    <div className="integrated-capture-container">
      <h2>ğŸ“¸ æ™ºèƒ½æ‹ç…§ç³»ç»Ÿ</h2>

      {isLoading && <div className="loading">â³ æ­£åœ¨åŠ è½½æ¨¡å‹...</div>}

      {error && (
        <div className="error-message">
          <p>âŒ {error}</p>
        </div>
      )}

      <div className="capture-content">
        <div className="video-container">
          <video ref={videoRef} style={{ display: "none" }} playsInline muted />
          <canvas
            ref={canvasRef}
            width={640}
            height={480}
            className="capture-canvas"
          />
        </div>

        <div
          className="captured-image-container"
          style={{
            display: state === CaptureState.COMPLETED ? "block" : "none",
          }}
        >
          <h3>ğŸ“· æ•è·çš„ç…§ç‰‡</h3>
          <canvas ref={capturedImageRef} className="captured-image" />
          <div className="capture-actions">
            <button onClick={handleDownload} className="download-btn">
              â¬‡ï¸ ä¸‹è½½ç…§ç‰‡
            </button>
            <button onClick={handleReset} className="reset-btn">
              ğŸ”„ é‡æ–°æ‹ç…§
            </button>
          </div>
        </div>
      </div>

      <div className="status-panel">
        <h3>ğŸ“Š çŠ¶æ€ä¿¡æ¯</h3>
        <div className="status-item">
          <span className="status-label">å½“å‰é˜¶æ®µï¼š</span>
          <span className={`status-value state-${state}`}>
            {state === CaptureState.IDLE && "ç­‰å¾…å¼€å§‹"}
            {state === CaptureState.DETECTING_BODY && "æ£€æµ‹å…¨èº«ä¸­"}
            {state === CaptureState.BODY_DETECTED && "å·²è¯†åˆ«å…¨èº«"}
            {state === CaptureState.DETECTING_GESTURE && "ç­‰å¾…æ‰‹åŠ¿"}
            {state === CaptureState.GESTURE_DETECTED && "æ£€æµ‹åˆ°OKæ‰‹åŠ¿"}
            {state === CaptureState.COUNTDOWN && "å€’è®¡æ—¶ä¸­"}
            {state === CaptureState.CAPTURE && "æ­£åœ¨æ‹ç…§"}
            {state === CaptureState.COMPLETED && "æ‹ç…§å®Œæˆ"}
          </span>
        </div>
      </div>

      <div className="instructions">
        <h3>ğŸ“ ä½¿ç”¨æµç¨‹</h3>
        <div className="instruction-steps">
          <div
            className={`step ${
              state === CaptureState.DETECTING_BODY ||
              state === CaptureState.BODY_DETECTED
                ? "active"
                : ""
            } ${
              state !== CaptureState.IDLE &&
              state !== CaptureState.DETECTING_BODY &&
              state !== CaptureState.BODY_DETECTED
                ? "completed"
                : ""
            }`}
          >
            <span className="step-number">1</span>
            <div className="step-content">
              <h4>å…¨èº«è¯†åˆ«</h4>
              <p>ç«™åœ¨æ‘„åƒå¤´å‰ï¼Œä¿æŒå®Œæ•´èº«ä½“åœ¨ç”»é¢ä¸­ï¼ŒæŒç»­1ç§’</p>
              <p className="step-note">
                ğŸ’¡ æ”¯æŒå¤šäººæ£€æµ‹ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æœ€å¤§çš„ç›®æ ‡
              </p>
            </div>
          </div>

          <div
            className={`step ${
              state === CaptureState.DETECTING_GESTURE ||
              state === CaptureState.GESTURE_DETECTED
                ? "active"
                : ""
            } ${
              state !== CaptureState.IDLE &&
              state !== CaptureState.DETECTING_BODY &&
              state !== CaptureState.BODY_DETECTED &&
              state !== CaptureState.DETECTING_GESTURE &&
              state !== CaptureState.GESTURE_DETECTED
                ? "completed"
                : ""
            }`}
          >
            <span className="step-number">2</span>
            <div className="step-content">
              <h4>OKæ‰‹åŠ¿</h4>
              <p>åšå‡ºOKæ‰‹åŠ¿ï¼ˆå¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡å½¢æˆåœ†åœˆï¼Œå…¶ä»–æ‰‹æŒ‡ä¼¸ç›´ï¼‰</p>
              <p className="step-note">âš ï¸ éœ€è¦ä¿æŒ3ç§’</p>
            </div>
          </div>

          <div
            className={`step ${
              state === CaptureState.COUNTDOWN ? "active" : ""
            } ${
              state === CaptureState.CAPTURE || state === CaptureState.COMPLETED
                ? "completed"
                : ""
            }`}
          >
            <span className="step-number">3</span>
            <div className="step-content">
              <h4>å€’è®¡æ—¶æ‹ç…§</h4>
              <p>5ç§’å€’è®¡æ—¶åè‡ªåŠ¨æ‹ç…§</p>
              <p className="step-note">ğŸ’¡ ä¿æŒå§¿åŠ¿å’Œä½ç½®</p>
            </div>
          </div>

          <div
            className={`step ${
              state === CaptureState.COMPLETED ? "active completed" : ""
            }`}
          >
            <span className="step-number">4</span>
            <div className="step-content">
              <h4>å®Œæˆ</h4>
              <p>æŸ¥çœ‹å’Œä¸‹è½½ç…§ç‰‡</p>
            </div>
          </div>
        </div>
      </div>

      {state !== CaptureState.IDLE && state !== CaptureState.COMPLETED && (
        <button onClick={handleReset} className="cancel-btn">
          âŒ å–æ¶ˆå¹¶é‡æ–°å¼€å§‹
        </button>
      )}
    </div>
  );
}
