import React from "react";
import { Hands, HAND_CONNECTIONS, type Results } from "@mediapipe/hands";
import { Pose, POSE_CONNECTIONS, type Results as PoseResults } from "@mediapipe/pose";
import { Camera } from "@mediapipe/camera_utils";
import { drawConnectors, drawLandmarks } from "@mediapipe/drawing_utils";
import { initializePose, calculateBodyRect, type BodyRect } from "../poseDetection";
import { CaptureState } from "../types/capture";
import { recognizeOKGesture } from "../utils/gestureRecognition";

interface UseMediaPipeProps {
  onCapture?: (canvas: HTMLCanvasElement) => void;
}

export function useMediaPipe({ onCapture }: UseMediaPipeProps = {}) {
  const videoRef = React.useRef<HTMLVideoElement>(null);
  const canvasRef = React.useRef<HTMLCanvasElement>(null);
  
  const [state, setState] = React.useState<CaptureState>(CaptureState.IDLE);
  const [isLoading, setIsLoading] = React.useState<boolean>(true);
  const [error, setError] = React.useState<string | null>(null);
  const [statusMessage, setStatusMessage] = React.useState<string>("");
  const [countdown, setCountdown] = React.useState<number>(5);

  const stateRef = React.useRef(state);
  const countdownRef = React.useRef(countdown);
  const statusMessageRef = React.useRef(statusMessage);

  const bodyDetectionStartTime = React.useRef<number | null>(null);
  const lastBodyDetectedTime = React.useRef<number | null>(null);
  const gestureDetectionStartTime = React.useRef<number | null>(null);
  const gestureLastLostTime = React.useRef<number | null>(null);
  const lastBodyRectRef = React.useRef<BodyRect | null>(null);
  const lastPoseLandmarksRef = React.useRef<PoseResults["poseLandmarks"] | null>(null);
  const frameCountRef = React.useRef<number>(0);

  const poseRef = React.useRef<Pose | null>(null);
  const handsRef = React.useRef<Hands | null>(null);
  const cameraRef = React.useRef<Camera | null>(null);
  
  // ‰øùÂ≠òÊúÄÊñ∞ÁöÑÁªìÊûúÁî®‰∫éÁªòÂà∂
  const latestPoseResultsRef = React.useRef<PoseResults | null>(null);
  const latestHandsResultsRef = React.useRef<Results | null>(null);
  const pendingDrawRef = React.useRef<boolean>(false);
  const frozenFrameRef = React.useRef<string | null>(null);

  React.useEffect(() => {
    stateRef.current = state;
    countdownRef.current = countdown;
    statusMessageRef.current = statusMessage;
  }, [state, countdown, statusMessage]);

  // Áªü‰∏ÄÁöÑÁªòÂà∂ÂáΩÊï∞ÔºåÂú® requestAnimationFrame ‰∏≠Ë∞ÉÁî®
  const draw = React.useCallback(() => {
    const canvas = canvasRef.current;
    const video = videoRef.current;
    if (!canvas || !video) {
      pendingDrawRef.current = false;
      return;
    }

    const ctx = canvas.getContext("2d");
    if (!ctx) {
      pendingDrawRef.current = false;
      return;
    }

    const currentState = stateRef.current;
    const poseResults = latestPoseResultsRef.current;
    const handsResults = latestHandsResultsRef.current;

    // Ê∏ÖÁ©∫ÁîªÂ∏ÉÂπ∂ÁªòÂà∂ËßÜÈ¢ëÂ∏ß
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    
    // ÂßãÁªà‰ΩøÁî® video ÂÖÉÁ¥†‰Ωú‰∏∫ÁªòÂà∂Ê∫êÔºå‰øùÊåÅ‰∏ÄËá¥ÊÄßÔºåÈÅøÂÖçÂàáÊç¢Êó∂Èó™ÁÉÅ
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // ÁªòÂà∂ pose landmarks ÂíåÂÖ®Ë∫´Ê°ÜÔºàÂú®ÈùûÊâãÂäøÊ£ÄÊµãÁä∂ÊÄÅÔºâ
    if (poseResults && poseResults.poseLandmarks && (
      currentState === CaptureState.IDLE ||
      currentState === CaptureState.DETECTING_BODY ||
      currentState === CaptureState.BODY_DETECTED ||
      currentState === CaptureState.COUNTDOWN ||
      currentState === CaptureState.COMPLETED
    )) {
      const rect = calculateBodyRect(poseResults.poseLandmarks, canvas.width, canvas.height);
      if (rect) {
        if (
          currentState === CaptureState.IDLE ||
          currentState === CaptureState.DETECTING_BODY ||
          currentState === CaptureState.BODY_DETECTED
        ) {
          drawConnectors(ctx, poseResults.poseLandmarks, POSE_CONNECTIONS, { color: "#00FF00", lineWidth: 2 });
          drawLandmarks(ctx, poseResults.poseLandmarks, { color: "#FF0000", radius: 3 });
          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 4;
          ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
          ctx.fillStyle = "#00FF00";
          ctx.font = "bold 12px Arial";
          ctx.fillText("ÂÖ®Ë∫´Â∑≤Ê£ÄÊµã", rect.x, rect.y - 10);
        } else if (currentState === CaptureState.COUNTDOWN) {
          ctx.strokeStyle = "#00FF00";
          ctx.lineWidth = 3;
          ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
        } else if (currentState === CaptureState.COMPLETED) {
          ctx.strokeStyle = "rgba(0, 255, 0, 0.3)";
          ctx.lineWidth = 2;
          ctx.strokeRect(rect.x, rect.y, rect.width, rect.height);
        }
      }
    }

    // ÁªòÂà∂ÂÖ®Ë∫´Ê°ÜÔºàÂú®ÊâãÂäøÊ£ÄÊµãÁä∂ÊÄÅÔºå‰ΩøÁî®ÁºìÂ≠òÁöÑÊ°ÜÔºâ
    if ((currentState === CaptureState.DETECTING_GESTURE || currentState === CaptureState.GESTURE_DETECTED) && lastBodyRectRef.current) {
      ctx.strokeStyle = "rgba(0, 255, 0, 0.8)";
      ctx.lineWidth = 3;
      ctx.strokeRect(lastBodyRectRef.current.x, lastBodyRectRef.current.y, lastBodyRectRef.current.width, lastBodyRectRef.current.height);
    }

    // ÁªòÂà∂ÊâãÈÉ® landmarks Âíå OK ÊâãÂäøÔºàÂú®ÊâãÂäøÊ£ÄÊµãÁä∂ÊÄÅÔºâ
    if (handsResults && handsResults.multiHandLandmarks && handsResults.multiHandLandmarks.length > 0 &&
        (currentState === CaptureState.DETECTING_GESTURE || currentState === CaptureState.GESTURE_DETECTED)) {
      for (const landmarks of handsResults.multiHandLandmarks) {
        drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: "#00FF00", lineWidth: 3 });
        drawLandmarks(ctx, landmarks, { color: "#FF0000", lineWidth: 1, radius: 4 });

        const gestureResult = recognizeOKGesture(landmarks);
        if (gestureResult.isOK) {
          ctx.font = "bold 24px Arial";
          ctx.fillStyle = "#00FF00";
          ctx.strokeStyle = "#000000";
          ctx.lineWidth = 2;
          const text = "OK üëå";
          const textWidth = ctx.measureText(text).width;
          ctx.strokeText(text, (canvas.width - textWidth) / 2, 80);
          ctx.fillText(text, (canvas.width - textWidth) / 2, 80);
        }
      }
    }

    // ÁªòÂà∂ÂÄíËÆ°Êó∂
    if (currentState === CaptureState.COUNTDOWN) {
      ctx.fillStyle = "#FFD700";
      ctx.strokeStyle = "#000000";
      ctx.lineWidth = 3;
      ctx.font = "bold 60px Arial";
      const text = countdownRef.current.toString();
      const textWidth = ctx.measureText(text).width;
      ctx.strokeText(text, (canvas.width - textWidth) / 2, canvas.height / 2);
      ctx.fillText(text, (canvas.width - textWidth) / 2, canvas.height / 2);
    }

    // ÁªòÂà∂Áä∂ÊÄÅÊ∂àÊÅØ
    const currentStatusMessage = statusMessageRef.current;
    if (currentStatusMessage && currentState !== CaptureState.COUNTDOWN) {
      ctx.fillStyle = "#FFFFFF";
      ctx.strokeStyle = "#000000";
      ctx.lineWidth = 2;
      ctx.font = "bold 16px Arial";
      const textWidth = ctx.measureText(currentStatusMessage).width;
      ctx.strokeText(currentStatusMessage, (canvas.width - textWidth) / 2, canvas.height - 50);
      ctx.fillText(currentStatusMessage, (canvas.width - textWidth) / 2, canvas.height - 50);
    }

    pendingDrawRef.current = false;
  }, []);

  // ËØ∑Ê±ÇÁªòÂà∂
  const requestDraw = React.useCallback(() => {
    if (!pendingDrawRef.current) {
      pendingDrawRef.current = true;
      requestAnimationFrame(draw);
    }
  }, [draw]);

  const onPoseResults = React.useCallback((results: PoseResults) => {
    const currentTime = Date.now();
    const currentState = stateRef.current;
    const canvas = canvasRef.current;
    if (!canvas) return;

    // ‰øùÂ≠òÊúÄÊñ∞ÁöÑÁªìÊûú
    latestPoseResultsRef.current = results;

    // Â§ÑÁêÜÂÖ®Ë∫´Ê£ÄÊµãÈÄªËæë
    if (results.poseLandmarks) {
      const rect = calculateBodyRect(results.poseLandmarks, canvas.width, canvas.height);
      if (rect) {
        lastBodyDetectedTime.current = currentTime;
        lastBodyRectRef.current = rect;
        lastPoseLandmarksRef.current = results.poseLandmarks;

        if (currentState !== CaptureState.COMPLETED) {
          if (currentState === CaptureState.IDLE) {
            setState(CaptureState.DETECTING_BODY);
            bodyDetectionStartTime.current = currentTime;
            setStatusMessage("Ê≠£Âú®Ê£ÄÊµãÂÖ®Ë∫´...");
          } else if (currentState === CaptureState.DETECTING_BODY) {
            if (bodyDetectionStartTime.current && currentTime - bodyDetectionStartTime.current >= 1000) {
              setState(CaptureState.DETECTING_GESTURE);
              setStatusMessage("‚úì Â∑≤ËØÜÂà´Âà∞ÂÖ®Ë∫´ÔºåËØ∑ÂÅöÂá∫OKÊâãÂäø");
            }
          }
        }
      }
    } else {
      // ÂÖ®Ë∫´‰∏¢Â§±Â§ÑÁêÜ
      if (currentState === CaptureState.DETECTING_BODY) {
        if (lastBodyDetectedTime.current && currentTime - lastBodyDetectedTime.current >= 1000) {
          setState(CaptureState.IDLE);
          bodyDetectionStartTime.current = null;
          lastBodyDetectedTime.current = null;
          lastPoseLandmarksRef.current = null;
          setStatusMessage("‚ùå Êú™ËØÜÂà´Âà∞ÂÖ®Ë∫´ÔºåËØ∑ÈáçÊñ∞Á´ô‰Ωç");
          setTimeout(() => setStatusMessage(""), 1500);
        }
      }
    }

    // ËØ∑Ê±ÇÁªòÂà∂
    requestDraw();
  }, [requestDraw]);

  const onHandsResults = React.useCallback((results: Results) => {
    const currentTime = Date.now();
    const currentState = stateRef.current;
    const video = videoRef.current;
    if (!video) return;

    // ‰øùÂ≠òÊúÄÊñ∞ÁöÑÁªìÊûú
    latestHandsResultsRef.current = results;

    if (currentState === CaptureState.DETECTING_GESTURE || currentState === CaptureState.GESTURE_DETECTED) {
      // ÊØè5Â∏ßÊ£ÄÊµã‰∏ÄÊ¨°poseÔºåÂáèÂ∞ëÊõ¥Êñ∞È¢ëÁéáÔºåÈÅøÂÖçÈó™Âä®
      frameCountRef.current++;
      if (frameCountRef.current % 5 === 0 && poseRef.current && video) {
        try {
          poseRef.current.send({ image: video }).catch(() => {});
        } catch (err) {}
      }

      // Ê£ÄÊü•ÂÖ®Ë∫´ÊòØÂê¶‰∏¢Â§±
      if (lastBodyDetectedTime.current && currentTime - lastBodyDetectedTime.current >= 1000) {
        setState(CaptureState.IDLE);
        bodyDetectionStartTime.current = null;
        lastBodyDetectedTime.current = null;
        gestureDetectionStartTime.current = null;
        frameCountRef.current = 0;
        setStatusMessage("‚ùå ÂÖ®Ë∫´‰∏¢Â§±ÔºåÈáçÊñ∞Ê£ÄÊµã");
        setTimeout(() => setStatusMessage(""), 1500);
        requestDraw();
        return;
      }

      // Ê£ÄÊµã OK ÊâãÂäø
      let isOKDetected = false;
      if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
        for (const landmarks of results.multiHandLandmarks) {
          const gestureResult = recognizeOKGesture(landmarks);
          if (gestureResult.isOK) {
            isOKDetected = true;
            break;
          }
        }
      }

      // Â§ÑÁêÜÊâãÂäøÁä∂ÊÄÅ
      if (isOKDetected) {
        gestureLastLostTime.current = null;
        
        if (currentState === CaptureState.DETECTING_GESTURE) {
          gestureDetectionStartTime.current = currentTime;
          setState(CaptureState.GESTURE_DETECTED);
        } else if (currentState === CaptureState.GESTURE_DETECTED && gestureDetectionStartTime.current) {
          const elapsed = currentTime - gestureDetectionStartTime.current;
          const remaining = Math.ceil((3000 - elapsed) / 1000);

          if (elapsed >= 3000) {
            setState(CaptureState.COUNTDOWN);
            setCountdown(5);
            setStatusMessage("ÂáÜÂ§áÊãçÁÖßÔºÅ");
          } else {
            setStatusMessage(`‰øùÊåÅOKÊâãÂäø ${remaining}s`);
          }
        }
      } else {
        // ÊâãÂäøÊú™Ê£ÄÊµãÂà∞
        if (currentState === CaptureState.GESTURE_DETECTED) {
          // Âè™ÊúâÂú®ÊâãÂäøÊåÅÁª≠‰∏¢Â§±300msÂêéÊâçÂàáÊç¢Áä∂ÊÄÅÔºåÈÅøÂÖçÈó™Âä®
          if (gestureLastLostTime.current === null) {
            gestureLastLostTime.current = currentTime;
          } else if (currentTime - gestureLastLostTime.current >= 300) {
            setState(CaptureState.DETECTING_GESTURE);
            gestureDetectionStartTime.current = null;
            gestureLastLostTime.current = null;
            setStatusMessage("ËØ∑ÂÅöÂá∫OKÊâãÂäø");
          }
        }
      }

      // ËØ∑Ê±ÇÁªòÂà∂
      requestDraw();
    }
  }, [requestDraw]);

  React.useEffect(() => {
    if (state === CaptureState.COUNTDOWN) {
      if (countdown > 0) {
        const timer = setTimeout(() => setCountdown(countdown - 1), 1000);
        return () => clearTimeout(timer);
      } else {
        // ÂÄíËÆ°Êó∂ÁªìÊùüÔºåÊçïËé∑ÂΩìÂâçÂ∏ß‰Ωú‰∏∫frozen frame
        // ‰ªé video ÂÖÉÁ¥†ÊçïËé∑ÔºåËÄå‰∏çÊòØ canvasÔºåËøôÊ†∑‰∏ç‰ºöÂåÖÂê´Á∫øÊ°ÜÂíåÂÄíËÆ°Êó∂
        const video = videoRef.current;
        const canvas = canvasRef.current;
        if (video && canvas) {
          try {
            // ÂàõÂª∫‰∏¥Êó∂ canvas Áî®‰∫éÊçïËé∑ÂíåË£ÅÂâ™
            const tempCanvas = document.createElement('canvas');
            const sourceWidth = video.videoWidth || 640;
            const sourceHeight = video.videoHeight || 480;
            
            // ËÆ°ÁÆó 9:16 Ë£ÅÂâ™Âå∫ÂüüÔºà‰∏é CameraFeed ‰∏≠ÁöÑÈÄªËæë‰∏ÄËá¥Ôºâ
            const targetAspect = 9 / 16;
            const sourceAspect = sourceWidth / sourceHeight;
            
            let cropWidth, cropHeight, cropX, cropY;
            if (sourceAspect > targetAspect) {
              // Source is wider, crop the width
              cropHeight = sourceHeight;
              cropWidth = sourceHeight * targetAspect;
              cropX = (sourceWidth - cropWidth) / 2;
              cropY = 0;
            } else {
              // Source is taller, crop the height
              cropWidth = sourceWidth;
              cropHeight = sourceWidth / targetAspect;
              cropX = 0;
              cropY = (sourceHeight - cropHeight) / 2;
            }
            
            // ËÆæÁΩÆ‰∏¥Êó∂ canvas ‰∏∫Ë£ÅÂâ™ÂêéÁöÑÂ∞∫ÂØ∏
            tempCanvas.width = cropWidth;
            tempCanvas.height = cropHeight;
            
            const tempCtx = tempCanvas.getContext('2d');
            if (tempCtx) {
              // ‰ªé video ÁªòÂà∂Ë£ÅÂâ™ÂêéÁöÑÂå∫ÂüüÂà∞‰∏¥Êó∂ canvas
              tempCtx.drawImage(
                video,
                cropX, cropY, cropWidth, cropHeight,
                0, 0, cropWidth, cropHeight
              );
              
              // ËΩ¨Êç¢‰∏∫ data URL
              const frozenFrameUrl = tempCanvas.toDataURL('image/png');
              frozenFrameRef.current = frozenFrameUrl;
              console.log('‚úÖ Frozen frame captured at countdown end (clean, 9:16 cropped)');
            }
          } catch (err) {
            console.error('‚ùå Failed to capture frozen frame:', err);
          }
        }
        // Á´ãÂç≥ËøõÂÖ•ÊãçÁÖß‰∏≠Áä∂ÊÄÅÊòæÁ§∫Âø´Èó®ÊïàÊûú
        setState(CaptureState.CAPTURING);
      }
    }
  }, [state, countdown]);

  // Handle capturing state - show shutter effect then take photo
  React.useEffect(() => {
    if (state === CaptureState.CAPTURING) {
      const captureTimer = setTimeout(() => {
        setState(CaptureState.CAPTURE);
      }, 300000); // 3ÁßíÊãçÁÖßÂª∂ËøüÔºåÊòæÁ§∫Âø´Èó®ÊïàÊûú
      return () => clearTimeout(captureTimer);
    }
  }, [state]);

  // Handle photo capture
  React.useEffect(() => {
    if (state === CaptureState.CAPTURE) {
      const video = videoRef.current;
      const canvas = canvasRef.current;
      if (video && canvas && lastBodyRectRef.current) {
        const tempCanvas = document.createElement("canvas");
        tempCanvas.width = video.videoWidth || 640;
        tempCanvas.height = video.videoHeight || 480;
        const tempCtx = tempCanvas.getContext("2d");
        if (tempCtx) {
          tempCtx.drawImage(video, 0, 0, tempCanvas.width, tempCanvas.height);
          const scaleX = tempCanvas.width / canvas.width;
          const scaleY = tempCanvas.height / canvas.height;
          const rect = lastBodyRectRef.current;
          const padding = 20;
          const x = Math.max(0, (rect.x - padding) * scaleX);
          const y = Math.max(0, (rect.y - padding) * scaleY);
          const width = Math.min(tempCanvas.width - x, (rect.width + padding * 2) * scaleX);
          const height = Math.min(tempCanvas.height - y, (rect.height + padding * 2) * scaleY);

          const resultCanvas = document.createElement("canvas");
          resultCanvas.width = width * 1.5;
          resultCanvas.height = height * 1.5;
          const resultCtx = resultCanvas.getContext("2d");
          if (resultCtx) {
            resultCtx.drawImage(tempCanvas, x, y, width, height, 0, 0, resultCanvas.width, resultCanvas.height);
            onCapture?.(resultCanvas);
          }
        }
        setState(CaptureState.COMPLETED);
        setStatusMessage("‚úì ÊãçÁÖßÂÆåÊàêÔºÅ");
      }
    }
  }, [state, onCapture]);

  // Track when video element is ready
  const [videoReady, setVideoReady] = React.useState(false);
  
  // Callback ref for video element
  const videoCallbackRef = React.useCallback((node: HTMLVideoElement | null) => {
    videoRef.current = node;
    if (node) {
      console.log('‚úÖ Video ÂÖÉÁ¥†Â∑≤ÈôÑÂä†Âà∞ DOM');
      setVideoReady(true);
    }
  }, []);

  // Initialization effect - runs when video is ready
  React.useEffect(() => {
    if (!videoReady) {
      console.log('Á≠âÂæÖ video ÂÖÉÁ¥†...');
      return;
    }

    let mounted = true;
    let camera: Camera | null = null;
    let hands: Hands | null = null;
    let pose: Pose | null = null;

    const initialize = async () => {
      try {
        console.log('=======ÂºÄÂßãÂàùÂßãÂåñ=======');
        console.log('videoRef.current:', videoRef.current);
        console.log('canvasRef.current:', canvasRef.current);
        
        if (!videoRef.current || !canvasRef.current) {
          throw new Error('Video Êàñ Canvas ÂÖÉÁ¥†Êú™ÊâæÂà∞');
        }

        const [poseInstance, handsInstance] = await Promise.all([
          initializePose(),
          (async () => {
            const h = new Hands({ locateFile: (file) => `/mediapipe/hands/${file}` });
            h.setOptions({ maxNumHands: 2, modelComplexity: 1, minDetectionConfidence: 0.7, minTrackingConfidence: 0.5 });
            return h;
          })(),
        ]);

        if (!mounted) return;
        pose = poseInstance;
        pose.onResults(onPoseResults);
        poseRef.current = pose;
        hands = handsInstance;
        hands.onResults(onHandsResults);
        handsRef.current = hands;

        console.log('ÂàõÂª∫ Camera ÂÆû‰æã...');
        camera = new Camera(videoRef.current, {
          onFrame: async () => {
            if (!mounted || !videoRef.current) return;
            const currentState = stateRef.current;
            
            try {
              // Âú®ÊâãÂäøÊ£ÄÊµãÈò∂ÊÆµÂêåÊó∂ËøêË°å pose Âíå hands
              if (
                currentState === CaptureState.DETECTING_GESTURE ||
                currentState === CaptureState.GESTURE_DETECTED
              ) {
                // ‰∏çÁ≠âÂæÖ pose ÂÆåÊàêÔºåËÆ©ÂÆÉÂú®ÂêéÂè∞ËøêË°å
                if (pose && mounted) {
                  pose.send({ image: videoRef.current }).catch(() => {});
                }
                // hands ÊòØ‰∏ªË¶ÅÂ§ÑÁêÜÔºåÁ≠âÂæÖÂÆÉÂÆåÊàê
                if (hands && mounted) {
                  await hands.send({ image: videoRef.current });
                }
              } else {
                // ÂÖ∂‰ªñÁä∂ÊÄÅÂè™ËøêË°å pose
                if (pose && mounted) {
                  await pose.send({ image: videoRef.current });
                }
              }
            } catch (err) {
              // ÂøΩÁï•ÈîôËØØÔºåÁªßÁª≠‰∏ã‰∏ÄÂ∏ß
            }
          },
          width: 640,
          height: 480,
        });

        console.log('Ê≠£Âú®ÂêØÂä®ÊëÑÂÉèÂ§¥...');
        await camera.start();
        console.log('‚úÖ ÊëÑÂÉèÂ§¥ÂêØÂä®ÊàêÂäüÔºÅ');
        
        cameraRef.current = camera;
        
        // È¢ÑÁÉ≠ hands Ê®°ÂûãÔºåÈÅøÂÖçÈ¶ñÊ¨°‰ΩøÁî®Êó∂Âç°È°ø
        console.log('È¢ÑÁÉ≠ hands Ê®°Âûã...');
        if (videoRef.current && hands) {
          try {
            await hands.send({ image: videoRef.current });
            console.log('‚úÖ hands Ê®°ÂûãÈ¢ÑÁÉ≠ÂÆåÊàê');
          } catch (err) {
            console.log('È¢ÑÁÉ≠Â§±Ë¥•Ôºå‰ΩÜ‰∏çÂΩ±Âìç‰ΩøÁî®');
          }
        }
        
        setIsLoading(false);
        setState(CaptureState.IDLE);
        setStatusMessage("Á´ôÂú®ÊëÑÂÉèÂ§¥ÂâçÂºÄÂßãÊ£ÄÊµã");
        console.log('‚úÖ ÂàùÂßãÂåñÂÆåÊàê');
      } catch (err) {
        console.error('‚ùå ÂàùÂßãÂåñÂ§±Ë¥•:', err);
        if (mounted) {
          setError(`Êó†Ê≥ïÂêØÂä®ÊëÑÂÉèÂ§¥ÊàñÂä†ËΩΩÊ®°Âûã: ${err instanceof Error ? err.message : String(err)}`);
          setIsLoading(false);
        }
      }
    };

    initialize();

    return () => {
      mounted = false;
      if (camera) camera.stop();
      setTimeout(() => {
        if (hands) hands.close();
        if (pose) pose.close();
      }, 100);
    };
  }, [videoReady, onHandsResults, onPoseResults]);

  
  const handleReset = () => {
    setState(CaptureState.IDLE);
    setStatusMessage("");
    setCountdown(5);
    bodyDetectionStartTime.current = null;
    lastBodyDetectedTime.current = null;
    gestureDetectionStartTime.current = null;
    gestureLastLostTime.current = null;
    lastBodyRectRef.current = null;
    lastPoseLandmarksRef.current = null;
    frameCountRef.current = 0;
    frozenFrameRef.current = null;
  };

  return {
    videoRef: videoCallbackRef,
    canvasRef,
    state,
    isLoading,
    error,
    statusMessage,
    countdown,
    handleReset,
    frozenFrame: frozenFrameRef.current,
  };
}
