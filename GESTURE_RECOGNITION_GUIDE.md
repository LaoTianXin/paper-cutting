# ğŸ¤š æ‰‹åŠ¿è¯†åˆ«å®ç°æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [Haar Cascade æ–¹æ¡ˆ](#haar-cascade-æ–¹æ¡ˆ)
2. [æ¨èæ–¹æ¡ˆï¼šMediaPipe](#æ¨èæ–¹æ¡ˆmediapipe)
3. [å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”](#å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”)
4. [å®ç°æ­¥éª¤](#å®ç°æ­¥éª¤)

---

## âš ï¸ é‡è¦æç¤º

**Haar Cascade å¯¹æ‰‹åŠ¿è¯†åˆ«çš„å±€é™æ€§ï¼š**

Haar Cascade ä¸»è¦ä¸º**äººè„¸æ£€æµ‹**è®¾è®¡ï¼Œå¯¹äºæ‰‹åŠ¿è¯†åˆ«å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š
- âŒ æ‰‹åŠ¿å§¿æ€å¤šå˜ï¼Œéš¾ä»¥ç”¨ç®€å•ç‰¹å¾æè¿°
- âŒ æ‰‹æŒ‡ç»†èŠ‚éš¾ä»¥æ•æ‰
- âŒ å…‰ç…§ã€èƒŒæ™¯å½±å“å¤§
- âŒ å‡†ç¡®ç‡è¾ƒä½
- âŒ å®˜æ–¹æä¾›çš„æ‰‹åŠ¿æ¨¡å‹éå¸¸å°‘

**ç»“è®º**ï¼šä¸æ¨èä½¿ç”¨ Haar Cascade åšæ‰‹åŠ¿è¯†åˆ«ï¼

---

## ğŸ” Haar Cascade æ–¹æ¡ˆ

### å®˜æ–¹æ¨¡å‹åº“

OpenCV å®˜æ–¹ GitHub ä»“åº“ï¼š
```
https://github.com/opencv/opencv/tree/master/data/haarcascades
```

**å¯ç”¨çš„æ¨¡å‹**ï¼š
- âœ… `haarcascade_frontalface_default.xml` - æ­£é¢äººè„¸
- âœ… `haarcascade_eye.xml` - çœ¼ç›
- âœ… `haarcascade_smile.xml` - ç¬‘å®¹
- âœ… `haarcascade_upperbody.xml` - ä¸ŠåŠèº«
- âœ… `haarcascade_fullbody.xml` - å…¨èº«
- âŒ **æ²¡æœ‰æ‰‹åŠ¿ç›¸å…³çš„æ¨¡å‹**

### ç¬¬ä¸‰æ–¹/ç¤¾åŒºæ¨¡å‹

ä¸€äº›å¼€å‘è€…è®­ç»ƒçš„æ‰‹åŠ¿æ¨¡å‹ï¼ˆè´¨é‡å‚å·®ä¸é½ï¼‰ï¼š

1. **GitHub æœç´¢**
   ```
   https://github.com/search?q=hand+gesture+haar+cascade
   ```

2. **å¯èƒ½çš„ä»“åº“**ï¼ˆéœ€è¦éªŒè¯ï¼‰ï¼š
   - `opencv_extra` é¡¹ç›®
   - ä¸ªäººå¼€å‘è€…åˆ†äº«çš„è®­ç»ƒç»“æœ
   - å­¦æœ¯é¡¹ç›®çš„å¼€æºä»£ç 

3. **ä¸‹è½½ç¤ºä¾‹**ï¼ˆå‡è®¾æ‰¾åˆ°ï¼‰ï¼š
   ```bash
   # ä¸‹è½½åˆ°ä½ çš„ public/models/ ç›®å½•
   wget https://raw.githubusercontent.com/.../hand_gesture.xml -O public/models/hand_gesture.xml
   ```

### è‡ªå·±è®­ç»ƒ Haar Cascade

å¦‚æœæ‰¾ä¸åˆ°åˆé€‚çš„æ¨¡å‹ï¼Œå¯ä»¥è‡ªå·±è®­ç»ƒï¼š

**éœ€è¦çš„å·¥å…·**ï¼š
- OpenCV è®­ç»ƒå·¥å…·
- å¤§é‡æ­£æ ·æœ¬å›¾ç‰‡ï¼ˆOK æ‰‹åŠ¿å›¾ç‰‡ï¼Œæ•°åƒå¼ ï¼‰
- å¤§é‡è´Ÿæ ·æœ¬å›¾ç‰‡ï¼ˆä¸åŒ…å«æ‰‹åŠ¿çš„å›¾ç‰‡ï¼‰

**è®­ç»ƒæ­¥éª¤**ï¼š
```bash
# 1. å‡†å¤‡æ•°æ®
# positive/ - åŒ…å« OK æ‰‹åŠ¿çš„å›¾ç‰‡ï¼ˆ3000+ å¼ ï¼‰
# negative/ - ä¸åŒ…å«æ‰‹åŠ¿çš„å›¾ç‰‡ï¼ˆ5000+ å¼ ï¼‰

# 2. åˆ›å»ºæè¿°æ–‡ä»¶
opencv_createsamples -info positive.txt -vec positive.vec

# 3. è®­ç»ƒ
opencv_traincascade -data classifier -vec positive.vec -bg negative.txt

# 4. å¾—åˆ° cascade.xml æ–‡ä»¶
```

**ç¼ºç‚¹**ï¼š
- è€—æ—¶é•¿ï¼ˆæ•°å°æ—¶åˆ°æ•°å¤©ï¼‰
- éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®
- å‡†ç¡®ç‡å¯èƒ½ä¸ç†æƒ³

---

## â­ æ¨èæ–¹æ¡ˆï¼šMediaPipe

**Google MediaPipe** æ˜¯ä¸“é—¨ä¸ºæ‰‹åŠ¿è¯†åˆ«è®¾è®¡çš„ç°ä»£è§£å†³æ–¹æ¡ˆï¼

### ä¸ºä»€ä¹ˆé€‰æ‹© MediaPipeï¼Ÿ

| ç‰¹æ€§ | Haar Cascade | MediaPipe |
|-----|-------------|-----------|
| å‡†ç¡®ç‡ | ä½ | â­â­â­â­â­ é«˜ |
| æ‰‹éƒ¨å…³é”®ç‚¹ | âŒ | âœ… 21 ä¸ªå…³é”®ç‚¹ |
| æ‰‹åŠ¿è¯†åˆ« | âŒ å·® | âœ… ä¼˜ç§€ |
| å®æ—¶æ€§èƒ½ | âœ… å¥½ | âœ… å¥½ |
| è®­ç»ƒéœ€æ±‚ | éœ€è¦è‡ªå·±è®­ç»ƒ | âœ… é¢„è®­ç»ƒæ¨¡å‹ |
| æ˜“ç”¨æ€§ | ä¸­ç­‰ | â­â­â­â­â­ ç®€å• |

### MediaPipe åŠŸèƒ½

```
æ£€æµ‹åˆ°çš„æ‰‹éƒ¨å…³é”®ç‚¹ï¼š
     8  12  16  20
     |   |   |   |
    7   11  15  19
    |   |   |   |
    6   10  14  18
     \  |   |  /
      \ |   | /
       \|   |/
    4   5   9  13  17
     \  |  /
      \ | /
       \|/
        0
    (æ‰‹è…•)
```

- âœ… æ£€æµ‹ 21 ä¸ªæ‰‹éƒ¨å…³é”®ç‚¹
- âœ… è¯†åˆ«æ‰‹åŠ¿ï¼ˆOKã€ç«–èµ·å¤§æ‹‡å¤´ã€Peaceç­‰ï¼‰
- âœ… å®æ—¶è·Ÿè¸ª
- âœ… æ”¯æŒå¤šåªæ‰‹
- âœ… æ— éœ€è®­ç»ƒï¼Œå¼€ç®±å³ç”¨

### å¿«é€Ÿé›†æˆ MediaPipe

**å®‰è£…**ï¼š
```bash
npm install @mediapipe/hands @mediapipe/camera_utils
# æˆ–
pnpm add @mediapipe/hands @mediapipe/camera_utils
```

**åŸºæœ¬ä½¿ç”¨**ï¼š
```typescript
import { Hands } from '@mediapipe/hands';
import { Camera } from '@mediapipe/camera_utils';

// åˆå§‹åŒ–
const hands = new Hands({
  locateFile: (file) => {
    return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
  }
});

hands.setOptions({
  maxNumHands: 2,              // æœ€å¤šæ£€æµ‹ 2 åªæ‰‹
  modelComplexity: 1,          // æ¨¡å‹å¤æ‚åº¦ 0-2
  minDetectionConfidence: 0.5, // æ£€æµ‹ç½®ä¿¡åº¦
  minTrackingConfidence: 0.5   // è·Ÿè¸ªç½®ä¿¡åº¦
});

// å¤„ç†ç»“æœ
hands.onResults((results) => {
  if (results.multiHandLandmarks) {
    for (const landmarks of results.multiHandLandmarks) {
      // landmarks: 21 ä¸ªå…³é”®ç‚¹çš„åæ ‡
      console.log(landmarks);
      
      // åˆ¤æ–­æ‰‹åŠ¿
      const gesture = recognizeGesture(landmarks);
      if (gesture === 'OK') {
        console.log('æ£€æµ‹åˆ° OK æ‰‹åŠ¿ï¼');
      }
    }
  }
});

// è¿æ¥æ‘„åƒå¤´
const camera = new Camera(videoElement, {
  onFrame: async () => {
    await hands.send({ image: videoElement });
  }
});
camera.start();
```

**è¯†åˆ« OK æ‰‹åŠ¿**ï¼š
```typescript
function recognizeGesture(landmarks: any): string {
  // landmarks[4] - å¤§æ‹‡æŒ‡å°–
  // landmarks[8] - é£ŸæŒ‡å°–
  // landmarks[0] - æ‰‹è…•
  
  const thumbTip = landmarks[4];
  const indexTip = landmarks[8];
  
  // è®¡ç®—å¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡çš„è·ç¦»
  const distance = Math.sqrt(
    Math.pow(thumbTip.x - indexTip.x, 2) +
    Math.pow(thumbTip.y - indexTip.y, 2)
  );
  
  // å¦‚æœè·ç¦»å¾ˆå°ï¼Œå¯èƒ½æ˜¯ OK æ‰‹åŠ¿
  if (distance < 0.05) {
    // è¿˜éœ€è¦æ£€æŸ¥å…¶ä»–æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´
    const middleTip = landmarks[12];
    const ringTip = landmarks[16];
    const pinkyTip = landmarks[20];
    
    // ç®€åŒ–çš„åˆ¤æ–­é€»è¾‘
    if (middleTip.y < landmarks[0].y) {
      return 'OK';
    }
  }
  
  return 'Unknown';
}
```

---

## ğŸ”„ å…¶ä»–æ–¹æ¡ˆå¯¹æ¯”

### 1. TensorFlow.js + Hand Pose Detection

**ä¼˜ç‚¹**ï¼š
- âœ… å¼ºå¤§çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- âœ… å¯ä»¥è®­ç»ƒè‡ªå®šä¹‰æ‰‹åŠ¿
- âœ… é«˜å‡†ç¡®ç‡

**ç¼ºç‚¹**ï¼š
- âš ï¸ æ¨¡å‹è¾ƒå¤§
- âš ï¸ éœ€è¦æ›´å¤šè®¡ç®—èµ„æº

**å®‰è£…**ï¼š
```bash
npm install @tensorflow/tfjs @tensorflow-models/hand-pose-detection
```

**ä½¿ç”¨**ï¼š
```typescript
import * as handPoseDetection from '@tensorflow-models/hand-pose-detection';

const model = handPoseDetection.SupportedModels.MediaPipeHands;
const detector = await handPoseDetection.createDetector(model);

const hands = await detector.estimateHands(video);
```

### 2. Handpose (TensorFlow.js)

**ä¼˜ç‚¹**ï¼š
- âœ… è½»é‡çº§
- âœ… æ˜“äºä½¿ç”¨

**ç¼ºç‚¹**ï¼š
- âš ï¸ åŠŸèƒ½ç›¸å¯¹ç®€å•

### 3. Haar Cascadeï¼ˆä¸æ¨èï¼‰

**ä¼˜ç‚¹**ï¼š
- âœ… è½»é‡çº§
- âœ… é€Ÿåº¦å¿«

**ç¼ºç‚¹**ï¼š
- âŒ å‡†ç¡®ç‡ä½
- âŒ éœ€è¦è‡ªå·±è®­ç»ƒ
- âŒ ä¸é€‚åˆæ‰‹åŠ¿è¯†åˆ«

---

## ğŸ“Š æ–¹æ¡ˆæ¨è

### æŒ‰ä½¿ç”¨åœºæ™¯é€‰æ‹©

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|-----|---------|------|
| **ç®€å•æ‰‹åŠ¿è¯†åˆ«** | MediaPipe | æœ€ä½³å¹³è¡¡ |
| **å¤æ‚æ‰‹åŠ¿/è‡ªå®šä¹‰** | TensorFlow.js | æ›´çµæ´» |
| **æç®€é¡¹ç›®** | Handpose | å¤Ÿç”¨å°±å¥½ |
| **å­¦ä¹ ç›®çš„** | Haar Cascade | äº†è§£ä¼ ç»Ÿæ–¹æ³• |

### ç»¼åˆæ¨èï¼šMediaPipe â­â­â­â­â­

ç†ç”±ï¼š
1. âœ… ä¸“ä¸ºæ‰‹åŠ¿è®¾è®¡
2. âœ… é«˜å‡†ç¡®ç‡
3. âœ… é¢„è®­ç»ƒæ¨¡å‹
4. âœ… ç®€å•æ˜“ç”¨
5. âœ… å®æ—¶æ€§èƒ½å¥½
6. âœ… Google å®˜æ–¹æ”¯æŒ

---

## ğŸš€ å®ç°æ­¥éª¤ï¼ˆMediaPipeï¼‰

### 1. å®‰è£…ä¾èµ–

```bash
pnpm add @mediapipe/hands @mediapipe/camera_utils @mediapipe/drawing_utils
```

### 2. åˆ›å»ºæ‰‹åŠ¿è¯†åˆ«ç»„ä»¶

```typescript
// src/HandGestureDetection.tsx
import React from 'react';
import { Hands, Results } from '@mediapipe/hands';
import { Camera } from '@mediapipe/camera_utils';

export default function HandGestureDetection() {
  const videoRef = React.useRef<HTMLVideoElement>(null);
  const canvasRef = React.useRef<HTMLCanvasElement>(null);
  const [gesture, setGesture] = React.useState<string>('');

  React.useEffect(() => {
    if (!videoRef.current || !canvasRef.current) return;

    const hands = new Hands({
      locateFile: (file) => {
        return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
      }
    });

    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    hands.onResults(onResults);

    const camera = new Camera(videoRef.current, {
      onFrame: async () => {
        await hands.send({ image: videoRef.current! });
      },
      width: 640,
      height: 480
    });
    camera.start();

    return () => {
      camera.stop();
    };
  }, []);

  function onResults(results: Results) {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d')!;
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.drawImage(results.image, 0, 0, canvas.width, canvas.height);

    if (results.multiHandLandmarks) {
      for (const landmarks of results.multiHandLandmarks) {
        // ç»˜åˆ¶æ‰‹éƒ¨å…³é”®ç‚¹
        drawLandmarks(ctx, landmarks);
        
        // è¯†åˆ«æ‰‹åŠ¿
        const detectedGesture = recognizeGesture(landmarks);
        setGesture(detectedGesture);
      }
    }
  }

  return (
    <div>
      <video ref={videoRef} style={{ display: 'none' }} />
      <canvas ref={canvasRef} width={640} height={480} />
      <div>æ£€æµ‹åˆ°çš„æ‰‹åŠ¿: {gesture}</div>
    </div>
  );
}
```

### 3. æ·»åŠ åˆ° App

```typescript
import HandGestureDetection from './HandGestureDetection';

// åœ¨ App.tsx ä¸­æ·»åŠ æ–°æ¨¡å¼
type Mode = "webcam" | "image" | "video" | "gesture";
```

---

## ğŸ¯ å…·ä½“æ‰‹åŠ¿è¯†åˆ«é€»è¾‘

### OK æ‰‹åŠ¿è¯†åˆ«

```typescript
function isOKGesture(landmarks: any[]): boolean {
  const thumbTip = landmarks[4];    // å¤§æ‹‡æŒ‡å°–
  const indexTip = landmarks[8];    // é£ŸæŒ‡å°–
  const middleTip = landmarks[12];  // ä¸­æŒ‡å°–
  const ringTip = landmarks[16];    // æ— åæŒ‡å°–
  const pinkyTip = landmarks[20];   // å°æŒ‡å°–
  const wrist = landmarks[0];       // æ‰‹è…•

  // 1. å¤§æ‹‡æŒ‡å’Œé£ŸæŒ‡æ¥è¿‘ï¼ˆå½¢æˆåœ†åœˆï¼‰
  const thumbIndexDist = distance(thumbTip, indexTip);
  const isCircle = thumbIndexDist < 0.05;

  // 2. å…¶ä»–ä¸‰æŒ‡ä¼¸ç›´ï¼ˆyåæ ‡å°äºæ‰‹è…•ï¼‰
  const isMiddleStraight = middleTip.y < wrist.y;
  const isRingStraight = ringTip.y < wrist.y;
  const isPinkyStraight = pinkyTip.y < wrist.y;

  return isCircle && isMiddleStraight && isRingStraight && isPinkyStraight;
}

function distance(p1: any, p2: any): number {
  return Math.sqrt(
    Math.pow(p1.x - p2.x, 2) +
    Math.pow(p1.y - p2.y, 2) +
    Math.pow(p1.z - p2.z, 2)
  );
}
```

### ç«–èµ·å¤§æ‹‡æŒ‡

```typescript
function isThumbsUp(landmarks: any[]): boolean {
  const thumbTip = landmarks[4];
  const thumbBase = landmarks[2];
  const wrist = landmarks[0];
  
  // å¤§æ‹‡æŒ‡å‘ä¸Š
  const thumbUp = thumbTip.y < thumbBase.y && thumbTip.y < wrist.y;
  
  // å…¶ä»–æ‰‹æŒ‡æ”¶èµ·
  const indexDown = landmarks[8].y > landmarks[6].y;
  const middleDown = landmarks[12].y > landmarks[10].y;
  
  return thumbUp && indexDown && middleDown;
}
```

### Peaceï¼ˆVï¼‰æ‰‹åŠ¿

```typescript
function isPeace(landmarks: any[]): boolean {
  const indexTip = landmarks[8];
  const middleTip = landmarks[12];
  const ringTip = landmarks[16];
  const pinkyTip = landmarks[20];
  const wrist = landmarks[0];
  
  // é£ŸæŒ‡å’Œä¸­æŒ‡ä¼¸ç›´
  const indexUp = indexTip.y < wrist.y;
  const middleUp = middleTip.y < wrist.y;
  
  // æ— åæŒ‡å’Œå°æŒ‡æ”¶èµ·
  const ringDown = ringTip.y > wrist.y;
  const pinkyDown = pinkyTip.y > wrist.y;
  
  return indexUp && middleUp && ringDown && pinkyDown;
}
```

---

## ğŸ’¡ æ€»ç»“

### å¿«é€Ÿç­”æ¡ˆ

**Q: åœ¨å“ªé‡Œè·å– OK æ‰‹åŠ¿çš„ XML æ–‡ä»¶ï¼Ÿ**

**A: ä¸æ¨èä½¿ç”¨ XMLï¼ˆHaar Cascadeï¼‰ï¼** 

**æ¨èä½¿ç”¨ MediaPipeï¼š**
```bash
pnpm add @mediapipe/hands
```

### é€‰æ‹©å»ºè®®

| ä½ çš„éœ€æ±‚ | æ¨èæ–¹æ¡ˆ |
|---------|---------|
| å¿«é€Ÿå®ç° | â­ MediaPipe |
| è‡ªå®šä¹‰æ‰‹åŠ¿ | TensorFlow.js |
| å­¦ä¹ ä¼ ç»Ÿç®—æ³• | è‡ªå·±è®­ç»ƒ Haar Cascade |
| ç”Ÿäº§ç¯å¢ƒ | â­ MediaPipe |

### ä¸‹ä¸€æ­¥

1. **å¦‚æœé€‰æ‹© MediaPipe**ï¼ˆæ¨èï¼‰ï¼š
   - æˆ‘å¯ä»¥å¸®ä½ é›†æˆåˆ°ç°æœ‰é¡¹ç›®
   - æ·»åŠ æ‰‹åŠ¿è¯†åˆ«æ¨¡å¼
   - å®ç° OKã€Peace ç­‰å¸¸è§æ‰‹åŠ¿

2. **å¦‚æœåšæŒ Haar Cascade**ï¼š
   - éœ€è¦è‡ªå·±è®­ç»ƒæ¨¡å‹
   - å‡†å¤‡å¤§é‡è®­ç»ƒæ•°æ®
   - æ•ˆæœå¯èƒ½ä¸ç†æƒ³

---

## ğŸ“š å‚è€ƒèµ„æº

### MediaPipe
- å®˜æ–¹æ–‡æ¡£: https://google.github.io/mediapipe/solutions/hands.html
- GitHub: https://github.com/google/mediapipe
- åœ¨çº¿æ¼”ç¤º: https://mediapipe.dev/demo/hands

### TensorFlow.js
- Hand Pose: https://github.com/tensorflow/tfjs-models/tree/master/hand-pose-detection
- æ–‡æ¡£: https://www.tensorflow.org/js

### OpenCV
- Haar Cascade è®­ç»ƒ: https://docs.opencv.org/3.4/dc/d88/tutorial_traincascade.html
- å®˜æ–¹æ¨¡å‹: https://github.com/opencv/opencv/tree/master/data

---

éœ€è¦æˆ‘å¸®ä½ å®ç° MediaPipe æ‰‹åŠ¿è¯†åˆ«å—ï¼Ÿæˆ‘å¯ä»¥ç«‹å³ä¸ºä½ çš„é¡¹ç›®æ·»åŠ è¿™ä¸ªåŠŸèƒ½ï¼ğŸš€

